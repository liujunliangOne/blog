<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hadoop之HDFS</title>
    <url>/2020/09/25/Hadoop%E4%B9%8BHDFS/</url>
    <content><![CDATA[<h2 id="HDFS简介"><a href="#HDFS简介" class="headerlink" title="HDFS简介"></a>HDFS简介</h2><p>HDFS <strong>(分布式文件系统)</strong> 是整个hadoop体系的基础，负责数据的存储与管理。HDFS有着高<a href="https://baike.baidu.com/item/%E5%AE%B9%E9%94%99%E6%80%A7/9131391">容错性</a>（fault-tolerant）的特点，并且设计用来部署在低廉的（low-cost）硬件上。而且它提供高吞吐量（high throughput）来访问应用程序的数据，适合那些有着超大数据集（large data set）的应用程序。</p>
<p>client：切分文件，访问HDFS时，首先与NameNode交互，获取目标文件的位置信息，然后与DataNode交互，读写数据</p>
<p>NameNode：master节点，每个HDFS集群只有一个，管理HDFS的名称空间和数据块映射信息，配置相关副本信息，处理客户端请求。</p>
<p>DataNode：slave节点，存储实际数据，并汇报状态信息给NameNode，默认一个文件会备份3份在不同的DataNode中，实现高可靠性和容错性。</p>
<p>Secondary NameNode：辅助NameNode，实现高可靠性，定期合并fsimage和fsedits，推送给NameNode；紧急情况下辅助和恢复NameNode，但其并非NameNode的热备份。</p>
<a id="more"></a>
<p>Hadoop 2为HDFS引入了两个重要的新功能 ——Federation和高可用（HA）：</p>
<ul>
<li>Federation允许集群中出现多个NameNode，之间相互独立且不需要互相协调，各自分工，管理自己的区域。 DataNode 被用作通用的数据块存储设备。每个 DataNode 要向集群中所有NameNode 注册，并发送心跳报告，执行所有 namenode的命令。</li>
<li>HDFS中的高可用性消除了Hadoop 1中存在的单点故障，其中，NameNode故障将导致集群中断。HDFS的高可用性提供故障转移功能（备用节点从失败的主NameNode接管工作的过程）以实现自动化。</li>
</ul>
<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p><img src="/assets/resource/hadoop/hdfs/command1.png"></p>
<p><img src="/assets/resource/hadoop/hdfs/command2.png"></p>
<p><img src="/assets/resource/hadoop/hdfs/command3.png"></p>
<h2 id="使用Java程序对HDFS文件系统进行操作"><a href="#使用Java程序对HDFS文件系统进行操作" class="headerlink" title="使用Java程序对HDFS文件系统进行操作"></a>使用Java程序对HDFS文件系统进行操作</h2><p>通过HDFS文件系统提供的Java API，我们可以完成如下的操作：</p>
<p>① 在HDFS文件系统中创建目录；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 在hdfs更目录下面创建test1文件夹</span><br><span class="line"> * @throws IOException</span><br><span class="line"> *&#x2F;</span><br><span class="line">@Test</span><br><span class="line">public void mkdir() throws IOException &#123;</span><br><span class="line">    Configuration conf &#x3D; new Configuration();</span><br><span class="line">    conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs:&#x2F;&#x2F;localhost:9500&quot;);</span><br><span class="line">    FileSystem fs &#x3D; FileSystem.newInstance(conf);</span><br><span class="line">    fs.mkdirs(new Path(&quot;&#x2F;test1&quot;));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>② 查看HDFS文件系统中的目录及文件信息；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 列出hdfs上所有的文件或文件夹：</span><br><span class="line"> * @throws IOException</span><br><span class="line"> *&#x2F;</span><br><span class="line">@Test</span><br><span class="line">public void listFiles() throws IOException &#123;</span><br><span class="line">    Configuration conf &#x3D; new Configuration();</span><br><span class="line">    conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs:&#x2F;&#x2F;localhost:9500&quot;);</span><br><span class="line">    FileSystem fs &#x3D; FileSystem.newInstance(conf);</span><br><span class="line">    &#x2F;&#x2F; true 表示递归查找 false 不进行递归查找</span><br><span class="line">    RemoteIterator&lt;LocatedFileStatus&gt; iterator &#x3D; fs.listFiles(new Path(&quot;&#x2F;&quot;), true);</span><br><span class="line">    while (iterator.hasNext())&#123;</span><br><span class="line">        LocatedFileStatus next &#x3D; iterator.next();</span><br><span class="line">        System.out.println(next.getPath());</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(&quot;----------------------------------------------------------&quot;);</span><br><span class="line">    FileStatus[] fileStatuses &#x3D; fs.listStatus(new Path(&quot;&#x2F;&quot;));</span><br><span class="line">    for (int i &#x3D; 0; i &lt; fileStatuses.length; i++) &#123;</span><br><span class="line">        FileStatus fileStatus &#x3D; fileStatuses[i];</span><br><span class="line">        System.out.println(fileStatus.getPath());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>③ 通过FileSystem API读取数据（下载文件）；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 将hdfs上文件下载到本地</span><br><span class="line"> *&#x2F;</span><br><span class="line">@Test</span><br><span class="line">public void download() throws IOException &#123;</span><br><span class="line">    Configuration conf &#x3D; new Configuration();</span><br><span class="line">    conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs:&#x2F;&#x2F;localhost:9500&quot;);</span><br><span class="line">    FileSystem fs &#x3D; FileSystem.newInstance(conf);</span><br><span class="line">    fs.copyToLocalFile(new Path(&quot;&#x2F;user&#x2F;wcinput&#x2F;rocketmq-externals-master.zip&quot;),new Path(&quot;C:&#x2F;Users&#x2F;Administrator&#x2F;Desktop&#x2F;userlogs&quot;));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p> ④通过FileSystem API上传数据到HDFS文件系统中；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 上传文件到hdfs上</span><br><span class="line"> *&#x2F;</span><br><span class="line">@Test</span><br><span class="line">public void upload() throws IOException &#123;</span><br><span class="line">    Configuration conf &#x3D; new Configuration();</span><br><span class="line">    conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs:&#x2F;&#x2F;localhost:9500&quot;);</span><br><span class="line">    FileSystem fs &#x3D; FileSystem.get(conf);</span><br><span class="line">    fs.copyFromLocalFile(new Path(&quot;C:&#x2F;Users&#x2F;Administrator&#x2F;Desktop&#x2F;rocketmq-externals-master.zip&quot;),new Path(&quot;&#x2F;user&#x2F;wcinput&quot;));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>⑤ 删除HDFS文件系统中的数据。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 删除hdfs上的文件</span><br><span class="line"> * @throws IOException</span><br><span class="line"> *&#x2F;</span><br><span class="line">@Test</span><br><span class="line">public void removeFile() throws IOException &#123;</span><br><span class="line">    Configuration conf &#x3D; new Configuration();</span><br><span class="line">    conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs:&#x2F;&#x2F;localhost:9500&quot;);</span><br><span class="line">    FileSystem fs &#x3D; FileSystem.newInstance(conf);</span><br><span class="line">    fs.delete(new Path(&quot;&#x2F;user&#x2F;wcinput&#x2F;rocketmq-externals-master.zip&quot;),false);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop入门教程</title>
    <url>/2020/09/25/Hadoop%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="1-、Hadoop-入门教程"><a href="#1-、Hadoop-入门教程" class="headerlink" title="1 、Hadoop 入门教程"></a>1 、Hadoop 入门教程</h1><p> Hadoop 是 Apache 开源组织的一个分布式计算开源框架 (<a href="http://hadoop.apache.org/">http://hadoop.apache.org/</a>) ，用 java 语言实现开源软件框架，实现在大量计算机组成的集群中对海量数据进行分布式计算。Hadoop 框架中最核心设计就是：HDFS 和 MapReduce ，HDFS 实现存储，而MapReduce实现原理分析处理，这两部分是 hadoop 的核心。数据在 Hadoop 中处理的流程可以简单的按照下图来理解：数据通过 Haddop 的集群处理后得到结果，它是一个高性能处理海量数据集的工具 。</p>
<p>（1）、HDSF  文件存儲</p>
<p>（2）、HBASE 非关系型数据库</p>
<p>（3）、MapReduce 离线计算</p>
<p>（4）、hive 数据查询</p>
<p>（5）、spark 内存级别计算</p>
<p>（6）、stom 实时计算</p>
<p>（7）、kafka 消息队列</p>
<a id="more"></a>
<h2 id="1-2-HDFS-文件系统"><a href="#1-2-HDFS-文件系统" class="headerlink" title="1.2 HDFS  文件系统"></a>1.2 HDFS  文件系统</h2><p>HDFS（Hadoop Distributed File System，Hadoop分布式文件系统），它是一个高度容错性的系统，适合部署在廉价的机器上。HDFS能提供高吞吐量的数据访问，适合那些有着超大数据集（largedata set）的应用程序。</p>
<p>HDFS的设计特点:</p>
<p>1、大数据文件，非常适合上T级别的大文件或者一堆大数据文件的存储。</p>
<p>2、文件分块存储，HDFS会将一个完整的大文件平均分块存储到不同计算器上，它的意义在于读取文件时可以同时从多个主机取不同区块的文件，多主机读取比单主机读取效率要高得多。</p>
<p>3、流式数据访问，一次写入多次读写，这种模式跟传统文件不同，它不支持动态改变文件内容，而是要求让文件一次写入就不做变化，要变化也只能在文件末添加内容。</p>
<p>4、廉价硬件，HDFS可以应用在普通PC机上，这种机制能够让给一些公司用几十台廉价的计算机就可以撑起一个大数据集群。</p>
<p>5、硬件故障，HDFS认为所有计算机都可能会出问题，为了防止某个主机失效读取不到该主机的块文件，它将同一个文件块副本分配到其它某几个主机上，如果其中一台主机失效，可以迅速找另一块副本取文件。</p>
<p>HDFS的master/slave构架:</p>
<p>一个HDFS集群是有一个Namenode和一定数目的Datanode组成。Namenode是一个中心服务器，负责管理文件系统的namespace和客户端对文件的访问。Datanode在集群中一般是一个节点一个，负责管理节点上它们附带的存储。在内部，一个文件其实分成一个或多个block，这些block存储在Datanode集合里。Namenode执行文件系统的namespace操作，例如打开、关闭、重命名文件和目录，同时决定block到具体Datanode节点的映射。Datanode在Namenode的指挥下进行block的创建、删除和复制。Namenode和Datanode都是设计成可以跑在普通的廉价的运行linux的机器上。</p>
<p>HDFS的关键元素:</p>
<p>1、 Block：将一个文件进行分块，通常是64M。</p>
<p>2、 NameNode：保存整个文件系统的目录信息、文件信息及分块信息，这是由唯一一台主机专门保存，当然这台主机如果出错，NameNode就失效了。在Hadoop2. 开始支持activity-standy模式—-如果主NameNode失效，启动备用主机运行NameNode。</p>
<p>3、 DataNode：分布在廉价的计算机上，用于存储Block块文件。</p>
<h2 id="1-3-MapReduce-文件系统"><a href="#1-3-MapReduce-文件系统" class="headerlink" title="1.3 MapReduce 文件系统"></a>1.3 MapReduce 文件系统</h2><p>MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行运算。MapReduce将分成两个部分”Map（映射）”和”Reduce（归约）”。</p>
<p>当你向MapReduce框架提交一个计算作业时，它会首先把计算作业拆分成若干个Map任务，然后分配到不同的节点上去执行，每一个Map任务处理输入数据中的一部分，当Map任务完成后，它会生成一些中间文件，这些中间文件将会作为Reduce任务的输入数据。Reduce任务的主要目标就是把前面若干个Map的输出汇总到一起并输出。</p>
<p>步骤1：首先对输入数据源进行切片</p>
<p>步骤2：master调度worker执行map任务</p>
<p>步骤3：worker读取输入源片段</p>
<p>步骤4：worker执行map任务，将任务输出保存在本地</p>
<p>步骤5：master调度worker执行reduce任务，reduce worker读取map任务的输出文件</p>
<p>步骤6：执行reduce任务，将任务输出保存到HDFS</p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Java mongodb 的基本操作</title>
    <url>/2020/09/07/Java%E4%BD%BF%E7%94%A8MongoDB/</url>
    <content><![CDATA[<h2 id="连接数据库"><a href="#连接数据库" class="headerlink" title="连接数据库"></a>连接数据库</h2><p>连接数据库，你需要指定数据库名称，如果指定的数据库不存在，mongo会自动创建数据库。</p>
<p>连接数据库的Java代码如下：</p>
<a id="more"></a>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import com.mongodb.MongoClient;</span><br><span class="line">import com.mongodb.client.MongoDatabase;</span><br><span class="line"></span><br><span class="line">public class MongoDBJDBC&#123;</span><br><span class="line">   public static void main( String args[] )&#123;</span><br><span class="line">      try&#123;   </span><br><span class="line">       &#x2F;&#x2F; 连接到 mongodb 服务</span><br><span class="line">         MongoClient mongoClient &#x3D; new MongoClient( &quot;localhost&quot; , 27017 );</span><br><span class="line">       </span><br><span class="line">         &#x2F;&#x2F; 连接到数据库</span><br><span class="line">         MongoDatabase mongoDatabase &#x3D; mongoClient.getDatabase(&quot;mycol&quot;);  </span><br><span class="line">       System.out.println(&quot;Connect to database successfully&quot;);</span><br><span class="line">        </span><br><span class="line">      &#125;catch(Exception e)&#123;</span><br><span class="line">        System.err.println( e.getClass().getName() + &quot;: &quot; + e.getMessage() );</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import java.util.ArrayList;  </span><br><span class="line">import java.util.List;  </span><br><span class="line">import com.mongodb.MongoClient;  </span><br><span class="line">import com.mongodb.MongoCredential;  </span><br><span class="line">import com.mongodb.ServerAddress;  </span><br><span class="line">import com.mongodb.client.MongoDatabase;  </span><br><span class="line">  </span><br><span class="line">public class MongoDBJDBC &#123;  </span><br><span class="line">    public static void main(String[] args)&#123;  </span><br><span class="line">        try &#123;  </span><br><span class="line">            &#x2F;&#x2F;连接到MongoDB服务 如果是远程连接可以替换“localhost”为服务器所在IP地址  </span><br><span class="line">            &#x2F;&#x2F;ServerAddress()两个参数分别为 服务器地址 和 端口  </span><br><span class="line">            ServerAddress serverAddress &#x3D; new ServerAddress(&quot;localhost&quot;,27017);  </span><br><span class="line">            List&lt;ServerAddress&gt; addrs &#x3D; new ArrayList&lt;ServerAddress&gt;();  </span><br><span class="line">            addrs.add(serverAddress);  </span><br><span class="line">              </span><br><span class="line">            &#x2F;&#x2F;MongoCredential.createScramSha1Credential()三个参数分别为 用户名 数据库名称 密码  </span><br><span class="line">            MongoCredential credential &#x3D; MongoCredential.createScramSha1Credential(&quot;username&quot;, &quot;databaseName&quot;, &quot;password&quot;.toCharArray());  </span><br><span class="line">            List&lt;MongoCredential&gt; credentials &#x3D; new ArrayList&lt;MongoCredential&gt;();  </span><br><span class="line">            credentials.add(credential);  </span><br><span class="line">              </span><br><span class="line">            &#x2F;&#x2F;通过连接认证获取MongoDB连接  </span><br><span class="line">            MongoClient mongoClient &#x3D; new MongoClient(addrs,credentials);  </span><br><span class="line">              </span><br><span class="line">            &#x2F;&#x2F;连接到数据库  </span><br><span class="line">            MongoDatabase mongoDatabase &#x3D; mongoClient.getDatabase(&quot;databaseName&quot;);  </span><br><span class="line">            System.out.println(&quot;Connect to database successfully&quot;);  </span><br><span class="line">        &#125; catch (Exception e) &#123;  </span><br><span class="line">            System.err.println( e.getClass().getName() + &quot;: &quot; + e.getMessage() );  </span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<h2 id="创建集合"><a href="#创建集合" class="headerlink" title="创建集合"></a>创建集合</h2><p>我们可以使用 com.mongodb.client.MongoDatabase 类中的createCollection()来创建集合</p>
<p>代码片段如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import com.mongodb.MongoClient;</span><br><span class="line">import com.mongodb.client.MongoDatabase;</span><br><span class="line"></span><br><span class="line">public class MongoDBJDBC&#123;</span><br><span class="line">   public static void main( String args[] )&#123;</span><br><span class="line">      try&#123;   </span><br><span class="line">      &#x2F;&#x2F; 连接到 mongodb 服务</span><br><span class="line">      MongoClient mongoClient &#x3D; new MongoClient( &quot;localhost&quot; , 27017 );</span><br><span class="line">         </span><br><span class="line">       </span><br><span class="line">      &#x2F;&#x2F; 连接到数据库</span><br><span class="line">      MongoDatabase mongoDatabase &#x3D; mongoClient.getDatabase(&quot;mycol&quot;);  </span><br><span class="line">      System.out.println(&quot;Connect to database successfully&quot;);</span><br><span class="line">      mongoDatabase.createCollection(&quot;test&quot;);</span><br><span class="line">      System.out.println(&quot;集合创建成功&quot;);</span><br><span class="line">        </span><br><span class="line">      &#125;catch(Exception e)&#123;</span><br><span class="line">        System.err.println( e.getClass().getName() + &quot;: &quot; + e.getMessage() );</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="获取集合"><a href="#获取集合" class="headerlink" title="获取集合"></a>获取集合</h2><p>我们可以使用com.mongodb.client.MongoDatabase类的 getCollection() 方法来获取一个集合</p>
<p>代码片段如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import org.bson.Document;</span><br><span class="line">import com.mongodb.MongoClient;</span><br><span class="line">import com.mongodb.client.MongoCollection;</span><br><span class="line">import com.mongodb.client.MongoDatabase;</span><br><span class="line"></span><br><span class="line">public class MongoDBJDBC&#123;</span><br><span class="line">   public static void main( String args[] )&#123;</span><br><span class="line">      try&#123;   </span><br><span class="line">       &#x2F;&#x2F; 连接到 mongodb 服务</span><br><span class="line">         MongoClient mongoClient &#x3D; new MongoClient( &quot;localhost&quot; , 27017 );</span><br><span class="line">       </span><br><span class="line">         &#x2F;&#x2F; 连接到数据库</span><br><span class="line">         MongoDatabase mongoDatabase &#x3D; mongoClient.getDatabase(&quot;mycol&quot;);  </span><br><span class="line">       System.out.println(&quot;Connect to database successfully&quot;);</span><br><span class="line">      </span><br><span class="line">       MongoCollection&lt;Document&gt; collection &#x3D; mongoDatabase.getCollection(&quot;test&quot;);</span><br><span class="line">       System.out.println(&quot;集合 test 选择成功&quot;);</span><br><span class="line">      &#125;catch(Exception e)&#123;</span><br><span class="line">        System.err.println( e.getClass().getName() + &quot;: &quot; + e.getMessage() );</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="插入文档"><a href="#插入文档" class="headerlink" title="插入文档"></a>插入文档</h2><p>我们可以使用com.mongodb.client.MongoCollection类的 insertMany() 方法来插入一个文档</p>
<p>代码片段如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.List;</span><br><span class="line">import org.bson.Document;</span><br><span class="line"></span><br><span class="line">import com.mongodb.MongoClient;</span><br><span class="line">import com.mongodb.client.MongoCollection;</span><br><span class="line">import com.mongodb.client.MongoDatabase;</span><br><span class="line"></span><br><span class="line">public class MongoDBJDBC&#123;</span><br><span class="line">   public static void main( String args[] )&#123;</span><br><span class="line">      try&#123;   </span><br><span class="line">         &#x2F;&#x2F; 连接到 mongodb 服务</span><br><span class="line">         MongoClient mongoClient &#x3D; new MongoClient( &quot;localhost&quot; , 27017 );</span><br><span class="line">         </span><br><span class="line">         &#x2F;&#x2F; 连接到数据库</span><br><span class="line">         MongoDatabase mongoDatabase &#x3D; mongoClient.getDatabase(&quot;mycol&quot;);  </span><br><span class="line">         System.out.println(&quot;Connect to database successfully&quot;);</span><br><span class="line">         </span><br><span class="line">         MongoCollection&lt;Document&gt; collection &#x3D; mongoDatabase.getCollection(&quot;test&quot;);</span><br><span class="line">         System.out.println(&quot;集合 test 选择成功&quot;);</span><br><span class="line">         &#x2F;&#x2F;插入文档  </span><br><span class="line">         &#x2F;** </span><br><span class="line">         * 1. 创建文档 org.bson.Document 参数为key-value的格式 </span><br><span class="line">         * 2. 创建文档集合List&lt;Document&gt; </span><br><span class="line">         * 3. 将文档集合插入数据库集合中 mongoCollection.insertMany(List&lt;Document&gt;) 插入单个文档可以用 mongoCollection.insertOne(Document) </span><br><span class="line">         * *&#x2F;</span><br><span class="line">         Document document &#x3D; new Document(&quot;title&quot;, &quot;MongoDB&quot;).  </span><br><span class="line">         append(&quot;description&quot;, &quot;database&quot;).  </span><br><span class="line">         append(&quot;likes&quot;, 100).  </span><br><span class="line">         append(&quot;by&quot;, &quot;Fly&quot;);  </span><br><span class="line">         List&lt;Document&gt; documents &#x3D; new ArrayList&lt;Document&gt;();  </span><br><span class="line">         documents.add(document);  </span><br><span class="line">         collection.insertMany(documents);  </span><br><span class="line">         System.out.println(&quot;文档插入成功&quot;);  </span><br><span class="line">      &#125;catch(Exception e)&#123;</span><br><span class="line">         System.err.println( e.getClass().getName() + &quot;: &quot; + e.getMessage() );</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="检索所有文档"><a href="#检索所有文档" class="headerlink" title="检索所有文档"></a>检索所有文档</h2><p>我们可以使用 com.mongodb.client.MongoCollection 类中的 find() 方法来获取集合中的所有文档。</p>
<p>此方法返回一个游标，所以你需要遍历这个游标。</p>
<p>代码片段如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import org.bson.Document;</span><br><span class="line">import com.mongodb.MongoClient;</span><br><span class="line">import com.mongodb.client.FindIterable;</span><br><span class="line">import com.mongodb.client.MongoCollection;</span><br><span class="line">import com.mongodb.client.MongoCursor;</span><br><span class="line">import com.mongodb.client.MongoDatabase;</span><br><span class="line"></span><br><span class="line">public class MongoDBJDBC&#123;</span><br><span class="line">   public static void main( String args[] )&#123;</span><br><span class="line">      try&#123;   </span><br><span class="line">         &#x2F;&#x2F; 连接到 mongodb 服务</span><br><span class="line">         MongoClient mongoClient &#x3D; new MongoClient( &quot;localhost&quot; , 27017 );</span><br><span class="line">         </span><br><span class="line">         &#x2F;&#x2F; 连接到数据库</span><br><span class="line">         MongoDatabase mongoDatabase &#x3D; mongoClient.getDatabase(&quot;mycol&quot;);  </span><br><span class="line">         System.out.println(&quot;Connect to database successfully&quot;);</span><br><span class="line">         </span><br><span class="line">         MongoCollection&lt;Document&gt; collection &#x3D; mongoDatabase.getCollection(&quot;test&quot;);</span><br><span class="line">         System.out.println(&quot;集合 test 选择成功&quot;);</span><br><span class="line">         </span><br><span class="line">         &#x2F;&#x2F;检索所有文档  </span><br><span class="line">         &#x2F;** </span><br><span class="line">         * 1. 获取迭代器FindIterable&lt;Document&gt; </span><br><span class="line">         * 2. 获取游标MongoCursor&lt;Document&gt; </span><br><span class="line">         * 3. 通过游标遍历检索出的文档集合 </span><br><span class="line">         * *&#x2F;  </span><br><span class="line">         FindIterable&lt;Document&gt; findIterable &#x3D; collection.find();  </span><br><span class="line">         MongoCursor&lt;Document&gt; mongoCursor &#x3D; findIterable.iterator();  </span><br><span class="line">         while(mongoCursor.hasNext())&#123;  </span><br><span class="line">            System.out.println(mongoCursor.next());  </span><br><span class="line">         &#125;  </span><br><span class="line">      </span><br><span class="line">      &#125;catch(Exception e)&#123;</span><br><span class="line">         System.err.println( e.getClass().getName() + &quot;: &quot; + e.getMessage() );</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h2><p>你可以使用 com.mongodb.client.MongoCollection 类中的 updateMany() 方法来更新集合中的文档。</p>
<p>代码片段如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import org.bson.Document;</span><br><span class="line">import com.mongodb.MongoClient;</span><br><span class="line">import com.mongodb.client.FindIterable;</span><br><span class="line">import com.mongodb.client.MongoCollection;</span><br><span class="line">import com.mongodb.client.MongoCursor;</span><br><span class="line">import com.mongodb.client.MongoDatabase;</span><br><span class="line">import com.mongodb.client.model.Filters;</span><br><span class="line"></span><br><span class="line">public class MongoDBJDBC&#123;</span><br><span class="line">   public static void main( String args[] )&#123;</span><br><span class="line">      try&#123;   </span><br><span class="line">         &#x2F;&#x2F; 连接到 mongodb 服务</span><br><span class="line">         MongoClient mongoClient &#x3D; new MongoClient( &quot;localhost&quot; , 27017 );</span><br><span class="line">         </span><br><span class="line">         &#x2F;&#x2F; 连接到数据库</span><br><span class="line">         MongoDatabase mongoDatabase &#x3D; mongoClient.getDatabase(&quot;mycol&quot;);  </span><br><span class="line">         System.out.println(&quot;Connect to database successfully&quot;);</span><br><span class="line">         </span><br><span class="line">         MongoCollection&lt;Document&gt; collection &#x3D; mongoDatabase.getCollection(&quot;test&quot;);</span><br><span class="line">         System.out.println(&quot;集合 test 选择成功&quot;);</span><br><span class="line">         </span><br><span class="line">         &#x2F;&#x2F;更新文档   将文档中likes&#x3D;100的文档修改为likes&#x3D;200   </span><br><span class="line">         collection.updateMany(Filters.eq(&quot;likes&quot;, 100), new Document(&quot;$set&quot;,new Document(&quot;likes&quot;,200)));  </span><br><span class="line">         &#x2F;&#x2F;检索查看结果  </span><br><span class="line">         FindIterable&lt;Document&gt; findIterable &#x3D; collection.find();  </span><br><span class="line">         MongoCursor&lt;Document&gt; mongoCursor &#x3D; findIterable.iterator();  </span><br><span class="line">         while(mongoCursor.hasNext())&#123;  </span><br><span class="line">            System.out.println(mongoCursor.next());  </span><br><span class="line">         &#125;  </span><br><span class="line">      </span><br><span class="line">      &#125;catch(Exception e)&#123;</span><br><span class="line">         System.err.println( e.getClass().getName() + &quot;: &quot; + e.getMessage() );</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="删除第一个文档"><a href="#删除第一个文档" class="headerlink" title="删除第一个文档"></a>删除第一个文档</h2><p>要删除集合中的第一个文档，首先你需要使用com.mongodb.DBCollection类中的 findOne()方法来获取第一个文档，然后使用remove 方法删除。</p>
<p>代码片段如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import org.bson.Document;</span><br><span class="line">import com.mongodb.MongoClient;</span><br><span class="line">import com.mongodb.client.FindIterable;</span><br><span class="line">import com.mongodb.client.MongoCollection;</span><br><span class="line">import com.mongodb.client.MongoCursor;</span><br><span class="line">import com.mongodb.client.MongoDatabase;</span><br><span class="line">import com.mongodb.client.model.Filters;</span><br><span class="line"></span><br><span class="line">public class MongoDBJDBC&#123;</span><br><span class="line">   public static void main( String args[] )&#123;</span><br><span class="line">      try&#123;   </span><br><span class="line">         &#x2F;&#x2F; 连接到 mongodb 服务</span><br><span class="line">         MongoClient mongoClient &#x3D; new MongoClient( &quot;localhost&quot; , 27017 );</span><br><span class="line"></span><br><span class="line">         &#x2F;&#x2F; 连接到数据库</span><br><span class="line">         MongoDatabase mongoDatabase &#x3D; mongoClient.getDatabase(&quot;mycol&quot;);  </span><br><span class="line">         System.out.println(&quot;Connect to database successfully&quot;);</span><br><span class="line"></span><br><span class="line">         MongoCollection&lt;Document&gt; collection &#x3D; mongoDatabase.getCollection(&quot;test&quot;);</span><br><span class="line">         System.out.println(&quot;集合 test 选择成功&quot;);</span><br><span class="line"></span><br><span class="line">         &#x2F;&#x2F;删除符合条件的第一个文档  </span><br><span class="line">         collection.deleteOne(Filters.eq(&quot;likes&quot;, 200));  </span><br><span class="line">         &#x2F;&#x2F;删除所有符合条件的文档  </span><br><span class="line">         collection.deleteMany (Filters.eq(&quot;likes&quot;, 200));  </span><br><span class="line">         &#x2F;&#x2F;检索查看结果  </span><br><span class="line">         FindIterable&lt;Document&gt; findIterable &#x3D; collection.find();  </span><br><span class="line">         MongoCursor&lt;Document&gt; mongoCursor &#x3D; findIterable.iterator();  </span><br><span class="line">         while(mongoCursor.hasNext())&#123;  </span><br><span class="line">           System.out.println(mongoCursor.next());  </span><br><span class="line">         &#125;  </span><br><span class="line">           </span><br><span class="line">      &#125;catch(Exception e)&#123;</span><br><span class="line">        System.err.println( e.getClass().getName() + &quot;: &quot; + e.getMessage() );</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>mongodb</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud 简单总结</title>
    <url>/2020/09/13/Spring%20cloud%20%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h2 id="什么是Spring-cloud"><a href="#什么是Spring-cloud" class="headerlink" title="什么是Spring cloud"></a>什么是Spring cloud</h2><blockquote>
<p>构建分布式系统不需要复杂和容易出错。Spring Cloud 为最常见的分布式系统模式提供了一种简单且易于接受的编程模型，帮助开发人员构建有弹性的、可靠的、协调的应用程序。Spring Cloud 构建于 Spring Boot 之上，使得开发者很容易入手并快速应用于生产中。</p>
</blockquote>
<p>个人理解：<strong>服务发现注册</strong> 、<strong>配置中心</strong> 、<strong>消息总线</strong> 、<strong>负载均衡</strong> 、<strong>断路器</strong> 、<strong>数据监控</strong> 等操作。我们能在 Spring Boot 的基础上轻松地实现微服务项目的构建。</p>
<a id="more"></a>


<h2 id="Sprng-Cloud-的服务发现框架——Eureka"><a href="#Sprng-Cloud-的服务发现框架——Eureka" class="headerlink" title="Sprng Cloud 的服务发现框架——Eureka"></a>Sprng Cloud 的服务发现框架——Eureka</h2><blockquote>
<p>Eureka是基于REST（代表性状态转移）的服务，主要在AWS云中用于定位服务，以实现负载均衡和中间层服务器的故障转移。我们称此服务为Eureka服务器。Eureka还带有一个基于Java的客户端组件Eureka Client，它使与服务的交互变得更加容易。客户端还具有一个内置的负载平衡器，可以执行基本的循环负载平衡。在Netflix，更复杂的负载均衡器将Eureka包装起来，以基于流量，资源使用，错误条件等多种因素提供加权负载均衡，以提供出色的弹性。</p>
</blockquote>
<p>个人理解：服务发现框架。</p>
<h2 id="Sprng-Cloud-的负载均衡之-Ribbon"><a href="#Sprng-Cloud-的负载均衡之-Ribbon" class="headerlink" title="Sprng Cloud 的负载均衡之 Ribbon"></a>Sprng Cloud 的负载均衡之 Ribbon</h2><blockquote>
<p>Ribbon 是 Netflix 公司的一个开源的负载均衡 项目，是一个客户端/进程内负载均衡器，<strong>运行在消费者端</strong>。</p>
</blockquote>
<p>个人理解：类似 nginx 不过 ribbon是一种<strong>集中式</strong>的负载均衡器， <strong>将所有请求都集中起来，然后再进行负载均衡</strong>。</p>
<h2 id="Sprng-Cloud的-Open-Feign"><a href="#Sprng-Cloud的-Open-Feign" class="headerlink" title="Sprng Cloud的 Open Feign"></a>Sprng Cloud的 Open Feign</h2><blockquote>
<p>OpenFeign 也是运行在消费者端的，使用 Ribbon 进行负载均衡，所以 OpenFeign 直接内置了 Ribbon。</p>
</blockquote>
<p>个人理解：消费者省去调用 <code>RestRemplate</code> 的 <code>API</code>，直接指定生产者方法</p>
<h2 id="Sprng-Cloud的-Hystrix"><a href="#Sprng-Cloud的-Hystrix" class="headerlink" title="Sprng Cloud的 Hystrix"></a>Sprng Cloud的 Hystrix</h2><blockquote>
<p>在分布式环境中，不可避免地会有许多服务依赖项中的某些失败。Hystrix是一个库，可通过添加等待时间容限和容错逻辑来帮助您控制这些分布式服务之间的交互。Hystrix通过隔离服务之间的访问点，停止服务之间的级联故障并提供后备选项来实现此目的，所有这些都可以提高系统的整体弹性。</p>
</blockquote>
<p>个人理解：就是一个能进行 <strong>熔断</strong> 和 <strong>降级</strong> 的中转仓库，提高整体系统的弹性。防止某个系统服务挂掉后，影响整体的系统运行直至<strong>服务雪崩</strong>。</p>
<h2 id="Sprng-Cloud的Zuul"><a href="#Sprng-Cloud的Zuul" class="headerlink" title="Sprng Cloud的Zuul"></a>Sprng Cloud的Zuul</h2><blockquote>
<p>ZUUL 是从设备和 web 站点到 Netflix 流应用后端的所有请求的前门。作为边界服务应用，ZUUL 是为了实现动态路由、监视、弹性和安全性而构建的。它还具有根据情况将请求路由到多个 Amazon Auto Scaling Groups（亚马逊自动缩放组，亚马逊的一种云计算方式） 的能力</p>
</blockquote>
<p>个人理解：介于客户端与服务器端之间，用于对请求进行<strong>鉴权</strong>、<strong>限流</strong>、 <strong>路由</strong>、<strong>监控</strong>等功能。最关键的就是 <strong>路由和过滤器</strong> 了.</p>
]]></content>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud 配置 hystrix-board</title>
    <url>/2020/09/13/SpringCloud%20%E9%85%8D%E7%BD%AE%20hystrix-board/</url>
    <content><![CDATA[<p>hystrix-board服务监控</p>
<p>1、创建新项目:hystrixdashboard。在application.properties文件中添加配置文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spring.application.name&#x3D;hystrixboard</span><br><span class="line">server.port&#x3D;6009</span><br></pre></td></tr></table></figure>

<p>2、在pom文件中添加依赖</p>
<a id="more"></a>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-web&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.7.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.7.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-actuator&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<p>3、配置servlet</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import com.netflix.hystrix.contrib.metrics.eventstream.HystrixMetricsStreamServlet;</span><br><span class="line">import org.springframework.boot.web.servlet.ServletRegistrationBean;</span><br><span class="line">import org.springframework.context.annotation.Bean;</span><br><span class="line">import org.springframework.stereotype.Component;</span><br><span class="line">@Component</span><br><span class="line">public class config &#123;</span><br><span class="line">    @Bean</span><br><span class="line">    public ServletRegistrationBean getServlet() &#123;</span><br><span class="line">        HystrixMetricsStreamServlet streamServlet &#x3D; new HystrixMetricsStreamServlet();</span><br><span class="line">        ServletRegistrationBean registrationBean &#x3D; new ServletRegistrationBean(streamServlet);</span><br><span class="line">        registrationBean.setLoadOnStartup(1);</span><br><span class="line">        registrationBean.addUrlMappings(&quot;&#x2F;hystrix.stream&quot;);</span><br><span class="line">        registrationBean.setName(&quot;HystrixMetricsStreamServlet&quot;);</span><br><span class="line">        return registrationBean;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>4、在主方法入口添加注解</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@EnableHystrixDashboard</span><br></pre></td></tr></table></figure>

<p>5、在消费者主方法入口添加注解 同时添加依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@EnableCircuitBreaker</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-actuator&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.7.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.netflix.hystrix&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hystrix-javanica&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<p>6、启动项目浏览器输入网址</p>
<blockquote>
<p><a href="http://localhost:6009/hystrix">http://localhost:6009/hystrix</a></p>
</blockquote>
<p><img src="/assets/resource/springcloud/hystrix.png"></p>
<p>7、输入消费者地址</p>
<blockquote>
<p><a href="http://localhost:6004/hystrix.stream">http://localhost:6004/hystrix.stream</a></p>
</blockquote>
<p><img src="/assets/resource/springcloud/hystrix2.png"></p>
]]></content>
      <tags>
        <tag>SpringCloud</tag>
        <tag>hystrix</tag>
        <tag>hystrix-board</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud之Hystrix</title>
    <url>/2020/09/18/SpringCloud%E4%B9%8BHystrix/</url>
    <content><![CDATA[<h2 id="Hystrix的请求合并"><a href="#Hystrix的请求合并" class="headerlink" title="Hystrix的请求合并"></a>Hystrix的请求合并</h2><h3 id="1、请求合并"><a href="#1、请求合并" class="headerlink" title="1、请求合并"></a>1、请求合并</h3><p>为什么要请求合并呢？为了减少线程和网络连接。开发者提供一个接口，实现批量请求。</p>
<p>同时有利也有弊端，请求合并会导致依赖服务的请求延迟增高，延迟的最大值就是合并时间窗口的大小，默认10ms,也可通过配置</p>
<blockquote>
<p>hystrix.collapser.default.timerDelayInMilliseconds</p>
</blockquote>
<p>进行修改属性值。</p>
<a id="more"></a>

<p>如果请求一次的依赖服务的平均时间是10ms，那么在最不乐观的情况下（合并窗口开始是请求加入等待队列）这次请求响应时间就会变成20ms。如果高并发的接口通过请求合并会极大提高系统的吞吐量，可以忽略合并时间窗口的开销，反之，并发量较低，对延迟敏感的接口不建议使用请求合并。</p>
<h3 id="2、贴代码，注解的形式实现请求合并"><a href="#2、贴代码，注解的形式实现请求合并" class="headerlink" title="2、贴代码，注解的形式实现请求合并"></a>2、贴代码，注解的形式实现请求合并</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Autowired</span><br><span class="line">ServiceFeignClient serviceFeignClient;</span><br><span class="line"></span><br><span class="line">@HystrixCollapser(batchMethod &#x3D; &quot;getNameBatch&quot;,scope &#x3D; com.netflix.hystrix.HystrixCollapser.Scope.GLOBAL,</span><br><span class="line">        collapserProperties &#x3D; &#123;@HystrixProperty(name &#x3D; &quot;timerDelayInMilliseconds&quot;, value &#x3D; &quot;200&quot;)&#125;)</span><br><span class="line">public Future&lt;RestfulResult&gt; batchGetName(String name) &#123;</span><br><span class="line">    System.out.println(&quot;被合并的请求&quot;);</span><br><span class="line">    throw new RuntimeException(&quot;This method body should not be executed&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@HystrixCommand</span><br><span class="line">public List&lt;RestfulResult&gt; getNameBatch(List&lt;String&gt; ids) &#123;</span><br><span class="line">    System.out.println(&quot;发送请求。。。参数为：&quot; + ids.toString() + &quot;,&quot; + Thread.currentThread().getName());</span><br><span class="line">    List&lt;RestfulResult&gt; list &#x3D; new ArrayList&lt;&gt;();</span><br><span class="line">    for (String id : ids) &#123;</span><br><span class="line">        ServiceInfo serviceInfo &#x3D; new ServiceInfo();</span><br><span class="line">        serviceInfo.setName(id);</span><br><span class="line">        RestfulResult hello &#x3D; serviceFeignClient.hello(serviceInfo);</span><br><span class="line">        System.out.println(&quot;发送请求。。。参数为：&quot; + hello.getData());</span><br><span class="line">        list.add(hello);</span><br><span class="line">    &#125;</span><br><span class="line">    return list;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@RequestMapping(&quot;&#x2F;testService&quot;)</span><br><span class="line">public void testService(HttpServletResponse response, ServiceInfo serviceInfo) throws ExecutionException, InterruptedException &#123;</span><br><span class="line">    &#x2F;**</span><br><span class="line">     *即使是调用一次也会被合并</span><br><span class="line">     *&#x2F;</span><br><span class="line">    HystrixRequestContext context &#x3D; HystrixRequestContext.initializeContext();</span><br><span class="line">    Future&lt;RestfulResult&gt; stringFuture &#x3D; hysService.batchGetName(serviceInfo.getName());</span><br><span class="line">    RestfulResult restfulResult &#x3D; stringFuture.get();</span><br><span class="line">    context.close();</span><br><span class="line">    CommUtils.printDataJason(response, restfulResult);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.commons&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;commons-lang3&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.4&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;fastjson&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.2.7&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.fasterxml.jackson.module&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;jackson-module-jaxb-annotations&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.0.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--Spring Cloud Config 客户端依赖--&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-config&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.0.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--Spring Boot Actuator，感应服务端变化--&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-actuator&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.0.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.7.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.netflix.hystrix&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hystrix-javanica&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<h3 id="3、测试方法"><a href="#3、测试方法" class="headerlink" title="3、测试方法"></a>3、测试方法</h3><p>（1）、postman进行借口请求</p>
<p>（2）、使用 jmete进行测试，下载链接  <a href="http://jmeter.apache.org/download_jmeter.cgi">http://jmeter.apache.org/download_jmeter.cgi</a></p>
<p><strong>常用的Hystrix属性：</strong></p>
<p>hystrix.command.default和hystrix.threadpool.default中的default为默认CommandKey</p>
<h2 id="Command-Properties："><a href="#Command-Properties：" class="headerlink" title="Command Properties："></a>Command Properties：</h2><h3 id="1-Execution相关的属性的配置："><a href="#1-Execution相关的属性的配置：" class="headerlink" title="1.Execution相关的属性的配置："></a>1.Execution相关的属性的配置：</h3><ul>
<li>hystrix.command.default.execution.isolation.strategy 隔离策略，默认是Thread, 可选Thread｜Semaphore</li>
<li>hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds 命令执行超时时间，默认1000ms</li>
<li>hystrix.command.default.execution.timeout.enabled 执行是否启用超时，默认启用true</li>
<li>hystrix.command.default.execution.isolation.thread.interruptOnTimeout 发生超时是是否中断，默认true</li>
<li>hystrix.command.default.execution.isolation.semaphore.maxConcurrentRequests 最大并发请求数，默认10，该参数当使用ExecutionIsolationStrategy.SEMAPHORE策略时才有效。如果达到最大并发请求数，请求会被拒绝。理论上选择semaphore size的原则和选择thread size一致，但选用semaphore时每次执行的单元要比较小且执行速度快（ms级别），否则的话应该用thread。<br>semaphore应该占整个容器（tomcat）的线程池的一小部分。</li>
</ul>
<h3 id="2-Fallback相关的属性"><a href="#2-Fallback相关的属性" class="headerlink" title="2.Fallback相关的属性"></a>2.Fallback相关的属性</h3><p>这些参数可以应用于Hystrix的THREAD和SEMAPHORE策略</p>
<ul>
<li>hystrix.command.default.fallback.isolation.semaphore.maxConcurrentRequests 如果并发数达到该设置值，请求会被拒绝和抛出异常并且fallback不会被调用。默认10</li>
<li>hystrix.command.default.fallback.enabled 当执行失败或者请求被拒绝，是否会尝试调用hystrixCommand.getFallback() 。默认true</li>
</ul>
<h3 id="3-Circuit-Breaker相关的属性"><a href="#3-Circuit-Breaker相关的属性" class="headerlink" title="3.Circuit Breaker相关的属性"></a>3.Circuit Breaker相关的属性</h3><ul>
<li>hystrix.command.default.circuitBreaker.enabled 用来跟踪circuit的健康性，如果未达标则让request短路。默认true</li>
<li>hystrix.command.default.circuitBreaker.requestVolumeThreshold 一个rolling window内最小的请求数。如果设为20，那么当一个rolling window的时间内（比如说1个rolling window是10秒）收到19个请求，即使19个请求都失败，也不会触发circuit break。默认20</li>
<li>hystrix.command.default.circuitBreaker.sleepWindowInMilliseconds 触发短路的时间值，当该值设为5000时，则当触发circuit break后的5000毫秒内都会拒绝request，也就是5000毫秒后才会关闭circuit。默认5000</li>
<li>hystrix.command.default.circuitBreaker.errorThresholdPercentage错误比率阀值，如果错误率&gt;=该值，circuit会被打开，并短路所有请求触发fallback。默认50</li>
<li>hystrix.command.default.circuitBreaker.forceOpen 强制打开熔断器，如果打开这个开关，那么拒绝所有request，默认false</li>
<li>hystrix.command.default.circuitBreaker.forceClosed 强制关闭熔断器 如果这个开关打开，circuit将一直关闭且忽略circuitBreaker.errorThresholdPercentage</li>
</ul>
<h3 id="4-Metrics相关参数"><a href="#4-Metrics相关参数" class="headerlink" title="4.Metrics相关参数"></a>4.Metrics相关参数</h3><ul>
<li>hystrix.command.default.metrics.rollingStats.timeInMilliseconds 设置统计的时间窗口值的，毫秒值，circuit break 的打开会根据1个rolling window的统计来计算。若rolling window被设为10000毫秒，则rolling window会被分成n个buckets，每个bucket包含success，failure，timeout，rejection的次数的统计信息。默认10000</li>
<li>hystrix.command.default.metrics.rollingStats.numBuckets 设置一个rolling window被划分的数量，若numBuckets＝10，rolling window＝10000，那么一个bucket的时间即1秒。必须符合rolling window % numberBuckets == 0。默认10</li>
<li>hystrix.command.default.metrics.rollingPercentile.enabled 执行时是否enable指标的计算和跟踪，默认true</li>
<li>hystrix.command.default.metrics.rollingPercentile.timeInMilliseconds 设置rolling percentile window的时间，默认60000</li>
<li>hystrix.command.default.metrics.rollingPercentile.numBuckets 设置rolling percentile window的numberBuckets。逻辑同上。默认6</li>
<li>hystrix.command.default.metrics.rollingPercentile.bucketSize 如果bucket size＝100，window＝10s，若这10s里有500次执行，只有最后100次执行会被统计到bucket里去。增加该值会增加内存开销以及排序的开销。默认100</li>
<li>hystrix.command.default.metrics.healthSnapshot.intervalInMilliseconds 记录health 快照（用来统计成功和错误绿）的间隔，默认500ms</li>
</ul>
<h3 id="5-Request-Context-相关参数"><a href="#5-Request-Context-相关参数" class="headerlink" title="5.Request Context 相关参数"></a>5.Request Context 相关参数</h3><p>hystrix.command.default.requestCache.enabled 默认true，需要重载getCacheKey()，返回null时不缓存<br>hystrix.command.default.requestLog.enabled 记录日志到HystrixRequestLog，默认true</p>
<h3 id="6-Collapser-Properties-相关参数"><a href="#6-Collapser-Properties-相关参数" class="headerlink" title="6.Collapser Properties 相关参数"></a>6.Collapser Properties 相关参数</h3><p>hystrix.collapser.default.maxRequestsInBatch 单次批处理的最大请求数，达到该数量触发批处理，默认Integer.MAX_VALUE<br>hystrix.collapser.default.timerDelayInMilliseconds 触发批处理的延迟，也可以为创建批处理的时间＋该值，默认10<br>hystrix.collapser.default.requestCache.enabled 是否对HystrixCollapser.execute() and HystrixCollapser.queue()的cache，默认true</p>
<h3 id="7-ThreadPool-相关参数"><a href="#7-ThreadPool-相关参数" class="headerlink" title="7.ThreadPool 相关参数"></a>7.ThreadPool 相关参数</h3><p>线程数默认值10适用于大部分情况（有时可以设置得更小），如果需要设置得更大，那有个基本得公式可以follow：<br>requests per second at peak when healthy × 99th percentile latency in seconds + some breathing room<br>每秒最大支撑的请求数 (99%平均响应时间 + 缓存值)<br>比如：每秒能处理1000个请求，99%的请求响应时间是60ms，那么公式是：<br>1000 （0.060+0.012）</p>
<p>基本得原则时保持线程池尽可能小，他主要是为了释放压力，防止资源被阻塞。<br>当一切都是正常的时候，线程池一般仅会有1到2个线程激活来提供服务</p>
<ul>
<li><ul>
<li>hystrix.threadpool.default.coreSize 并发执行的最大线程数，默认10</li>
<li>hystrix.threadpool.default.maxQueueSize BlockingQueue的最大队列数，当设为－1，会使用SynchronousQueue，值为正时使用LinkedBlcokingQueue。该设置只会在初始化时有效，之后不能修改threadpool的queue size，除非reinitialising thread executor。默认－1。</li>
<li>hystrix.threadpool.default.queueSizeRejectionThreshold 即使maxQueueSize没有达到，达到queueSizeRejectionThreshold该值后，请求也会被拒绝。因为maxQueueSize不能被动态修改，这个参数将允许我们动态设置该值。if maxQueueSize == -1，该字段将不起作用</li>
<li>hystrix.threadpool.default.keepAliveTimeMinutes 如果corePoolSize和maxPoolSize设成一样（默认实现）该设置无效。如果通过plugin（<a href="https://github.com/Netflix/Hystrix/wiki/Plugins%EF%BC%89%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E5%AE%9E%E7%8E%B0%EF%BC%8C%E8%AF%A5%E8%AE%BE%E7%BD%AE%E6%89%8D%E6%9C%89%E7%94%A8%EF%BC%8C%E9%BB%98%E8%AE%A41">https://github.com/Netflix/Hystrix/wiki/Plugins）使用自定义实现，该设置才有用，默认1</a>.</li>
<li>hystrix.threadpool.default.metrics.rollingStats.timeInMilliseconds 线程池统计指标的时间，默认10000</li>
<li>hystrix.threadpool.default.metrics.rollingStats.numBuckets 将rolling window划分为n个buckets，默认10</li>
</ul>
</li>
</ul>
]]></content>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Hystrix</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring 常用注解</title>
    <url>/2020/08/24/Spring%E6%B3%A8%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="Spring部分"><a href="#Spring部分" class="headerlink" title="Spring部分"></a>Spring部分</h2><h3 id="1、声明bean的注解"><a href="#1、声明bean的注解" class="headerlink" title="1、声明bean的注解"></a>1、声明bean的注解</h3><blockquote>
<p>@Component 组件，没有明确的角色</p>
</blockquote>
<blockquote>
<p>@Service 在业务逻辑层使用（service层）</p>
</blockquote>
<blockquote>
<p>@Repository 在数据访问层使用（dao层）</p>
</blockquote>
<blockquote>
<p>@Controller 在展现层使用，控制器的声明（C）</p>
</blockquote>
<a id="more"></a>

<h3 id="2、注入bean的注解"><a href="#2、注入bean的注解" class="headerlink" title="2、注入bean的注解"></a>2、注入bean的注解</h3><blockquote>
<p>@Autowired：由Spring提供</p>
</blockquote>
<blockquote>
<p>@Inject：由JSR-330提供</p>
</blockquote>
<blockquote>
<p>@Resource：由JSR-250提供</p>
</blockquote>
<blockquote>
<p>都可以注解在set方法和属性上，推荐注解在属性上（一目了然，少写代码）。</p>
</blockquote>
<h3 id="3、java配置类相关注解"><a href="#3、java配置类相关注解" class="headerlink" title="3、java配置类相关注解"></a>3、java配置类相关注解</h3><blockquote>
<p>@Configuration 声明当前类为配置类，相当于xml形式的Spring配置（类上）</p>
</blockquote>
<blockquote>
<p>@Bean 注解在方法上，声明当前方法的返回值为一个bean，替代xml中的方式（方法上）</p>
</blockquote>
<blockquote>
<p>@Configuration 声明当前类为配置类，其中内部组合了@Component注解，表明这个类是一个bean（类上）</p>
</blockquote>
<blockquote>
<p>@ComponentScan 用于对Component进行扫描，相当于xml中的（类上）</p>
</blockquote>
<blockquote>
<p>@WishlyConfiguration 为@Configuration与@ComponentScan的组合注解，可以替代这两个注解</p>
</blockquote>
<h3 id="4、切面（AOP）相关注解"><a href="#4、切面（AOP）相关注解" class="headerlink" title="4、切面（AOP）相关注解"></a>4、切面（AOP）相关注解</h3><blockquote>
<p>Spring支持AspectJ的注解式切面编程。</p>
</blockquote>
<blockquote>
<p>@Aspect 声明一个切面（类上） 使用@After、@Before、@Around定义建言（advice），可直接将拦截规则（切点）作为参数。</p>
</blockquote>
<blockquote>
<p>@After 在方法执行之后执行（方法上） @Before 在方法执行之前执行（方法上） @Around 在方法执行之前与之后执行（方法上）</p>
</blockquote>
<blockquote>
<p>@PointCut 声明切点 在java配置类中使用@EnableAspectJAutoProxy注解开启Spring对AspectJ代理的支持（类上）</p>
</blockquote>
<h3 id="5、-Bean的属性支持"><a href="#5、-Bean的属性支持" class="headerlink" title="5、@Bean的属性支持"></a>5、@Bean的属性支持</h3><blockquote>
<p>@Validated</p>
</blockquote>
<blockquote>
<p>@Primary：自动装配时当出现多个Bean候选者时，被注解为@Primary的Bean将作为首选者，否则将抛出异常</p>
</blockquote>
<blockquote>
<p>@Configuration把一个类作为一个IoC容器，它的某个方法头上如果注册了@Bean，就会作为这个Spring容器中的Bean。</p>
</blockquote>
<blockquote>
<p>@Lazy(true) 表示延迟初始化</p>
</blockquote>
<blockquote>
<p>@Scope 设置Spring容器如何新建Bean实例（方法上，得有@Bean） 其设置类型包括：</p>
</blockquote>
<blockquote>
<p>Singleton （单例,一个Spring容器中只有一个bean实例，默认模式）, Protetype （每次调用新建一个bean）, Request （web项目中，给每个http request新建一个bean）, Session （web项目中，给每个http session新建一个bean）, GlobalSession（给每一个 global http session新建一个Bean实例）</p>
</blockquote>
<blockquote>
<p>@StepScope 在Spring Batch中还有涉及</p>
</blockquote>
<blockquote>
<p>@PostConstruct 由JSR-250提供，在构造函数执行完之后执行，等价于xml配置文件中bean的initMethod</p>
</blockquote>
<blockquote>
<p>@PreDestory 由JSR-250提供，在Bean销毁之前执行，等价于xml配置文件中bean的destroyMethod</p>
</blockquote>
<blockquote>
<p>@Async异步方法调用</p>
</blockquote>
<h3 id="6、-Value注解"><a href="#6、-Value注解" class="headerlink" title="6、@Value注解"></a>6、@Value注解</h3><blockquote>
<p>@Value 为属性注入值（属性上） 支持如下方式的注入： 》注入普通字符 @Value(“colcol”)String name;</p>
</blockquote>
<blockquote>
<p>注入操作系统属性  @Value(“#{systemProperties[‘os.name’]}”)String osName;</p>
</blockquote>
<blockquote>
<p>注入表达式结果 @Value(“#{ T(java.lang.Math).random() * 100 }”) String randomNumber;</p>
</blockquote>
<blockquote>
<p>注入其它bean属性@Value(“#{domeClass.name}”)String name;</p>
</blockquote>
<blockquote>
<p>注入文件资源 @Value(“classpath:com/hgs/hello/test.txt”)String Resource file;</p>
</blockquote>
<blockquote>
<p>注入网站资源 @Value(“<a href="https://alibroadcast.com&quot;)resource/">https://alibroadcast.com&quot;)Resource</a> url;</p>
</blockquote>
<blockquote>
<p>注入配置文件Value(“${book.name}”)String bookName;</p>
</blockquote>
<blockquote>
<p>注入配置使用方法： ① 编写配置文件（test.properties）book.name=《三体》</p>
</blockquote>
<blockquote>
<p>@PropertySource 加载配置文件(类上)</p>
</blockquote>
<blockquote>
<p>@PropertySource(“classpath:com/test1.propertie”)</p>
</blockquote>
<blockquote>
<p>还需配置一个PropertySourcesPlaceholderConfigurer的bean。</p>
</blockquote>
<h3 id="7、环境切换"><a href="#7、环境切换" class="headerlink" title="7、环境切换"></a>7、环境切换</h3><blockquote>
<p>@Profile 通过设定Environment的ActiveProfiles来设定当前context需要使用的配置环境。（类或方法上）</p>
</blockquote>
<blockquote>
<p>@Conditional Spring4中可以使用此注解定义条件话的bean，通过实现Condition接口，并重写matches方法，从而决定该bean是否被实例化。（方法上）</p>
</blockquote>
<h3 id="8、异步相关"><a href="#8、异步相关" class="headerlink" title="8、异步相关"></a>8、异步相关</h3><blockquote>
<p>@EnableAsync 配置类中，通过此注解开启对异步任务的支持，叙事性AsyncConfigurer接口（类上）</p>
</blockquote>
<blockquote>
<p>@Async 在实际执行的bean方法使用该注解来申明其是一个异步任务（方法上或类上所有的方法都将异步，需要@EnableAsync开启异步任务）</p>
</blockquote>
<h3 id="9、定时任务相关"><a href="#9、定时任务相关" class="headerlink" title="9、定时任务相关"></a>9、定时任务相关</h3><blockquote>
<p>@EnableScheduling 在配置类上使用，开启计划任务的支持（类上）</p>
</blockquote>
<blockquote>
<p>@Scheduled 来申明这是一个任务，包括cron,fixDelay,fixRate等类型（方法上，需先开启计划任务的支持）</p>
</blockquote>
<h3 id="10、-Enable-注解说明"><a href="#10、-Enable-注解说明" class="headerlink" title="10、@Enable*注解说明"></a>10、@Enable*注解说明</h3><blockquote>
<p>这些注解主要用来开启对xxx的支持。 @EnableAspectJAutoProxy 开启对AspectJ自动代理的支持</p>
</blockquote>
<blockquote>
<p>@EnableAsync 开启异步方法的支持</p>
</blockquote>
<blockquote>
<p>@EnableScheduling 开启计划任务的支持</p>
</blockquote>
<blockquote>
<p>@EnableWebMvc 开启Web MVC的配置支持</p>
</blockquote>
<blockquote>
<p>@EnableConfigurationProperties 开启对@ConfigurationProperties注解配置Bean的支持</p>
</blockquote>
<blockquote>
<p>@EnableJpaRepositories 开启对SpringData JPA Repository的支持</p>
</blockquote>
<blockquote>
<p>@EnableTransactionManagement 开启注解式事务的支持</p>
</blockquote>
<blockquote>
<p>@EnableTransactionManagement 开启注解式事务的支持</p>
</blockquote>
<blockquote>
<p>@EnableCaching 开启注解式的缓存支持</p>
</blockquote>
<h3 id="11、测试相关注解"><a href="#11、测试相关注解" class="headerlink" title="11、测试相关注解"></a>11、测试相关注解</h3><blockquote>
<p>@RunWith 运行器，Spring中通常用于对JUnit的支持</p>
</blockquote>
<blockquote>
<p>@RunWith(SpringJUnit4ClassRunner.class)</p>
</blockquote>
<blockquote>
<p>@ContextConfiguration 用来加载配置ApplicationContext，其中classes属性用来加载配置类</p>
</blockquote>
<blockquote>
<p>@ContextConfiguration(classes={TestConfig.class})</p>
</blockquote>
<h2 id="SpringMVC部分"><a href="#SpringMVC部分" class="headerlink" title="SpringMVC部分"></a>SpringMVC部分</h2><blockquote>
<p>@EnableWebMvc 在配置类中开启Web MVC的配置支持，如一些ViewResolver或者MessageConverter等，若无此句，重写WebMvcConfigurerAdapter方法（用于对SpringMVC的配置）。</p>
</blockquote>
<blockquote>
<p>@Controller 声明该类为SpringMVC中的Controller</p>
</blockquote>
<blockquote>
<p>@RequestMapping 用于映射Web请求，包括访问路径和参数（类或方法上）</p>
</blockquote>
<blockquote>
<p>@ResponseBody 支持将返回值放在response内，而不是一个页面，通常用户返回json数据（返回值旁或方法上）</p>
</blockquote>
<blockquote>
<p>@RequestBody 允许request的参数在request体中，而不是在直接连接在地址后面。（放在参数前）</p>
</blockquote>
<blockquote>
<p>@PathVariable 用于接收路径参数，比如@RequestMapping(“/hello/{name}”)申明的路径，将注解放在参数中前，即可获取该值，通常作为Restful的接口实现方法。</p>
</blockquote>
<blockquote>
<p>@RestController 该注解为一个组合注解，相当于@Controller和@ResponseBody的组合，注解在类上，意味着，该Controller的所有方法都默认加上了@ResponseBody。</p>
</blockquote>
<blockquote>
<p>@ControllerAdvice 通过该注解，我们可以将对于控制器的全局配置放置在同一个位置，注解了@Controller的类的方法可使用@ExceptionHandler、@InitBinder、@ModelAttribute注解到方法上， 这对所有注解了 @RequestMapping的控制器内的方法有效。</p>
</blockquote>
<blockquote>
<p>@ExceptionHandler 用于全局处理控制器里的异常</p>
</blockquote>
<blockquote>
<p>@InitBinder 用来设置WebDataBinder，WebDataBinder用来自动绑定前台请求参数到Model中。</p>
</blockquote>
<blockquote>
<p>@ModelAttribute 本来的作用是绑定键值对到Model里，在@ControllerAdvice中是让全局的@RequestMapping都能获得在此处设置的键值对。</p>
</blockquote>
<blockquote>
<p>@PostMapping</p>
</blockquote>
<blockquote>
<p>@GetMapping</p>
</blockquote>
]]></content>
      <tags>
        <tag>spring</tag>
        <tag>springMvc</tag>
      </tags>
  </entry>
  <entry>
    <title>Windows 下部署RocketMq</title>
    <url>/2020/09/13/Windows%20%E4%B8%8B%E9%83%A8%E7%BD%B2RocketMq/</url>
    <content><![CDATA[<h2 id="1、环境"><a href="#1、环境" class="headerlink" title="1、环境"></a>1、环境</h2><p>Windows系统、JDK1.8、Maven 、Git</p>
<h2 id="2、RocketMq部署"><a href="#2、RocketMq部署" class="headerlink" title="2、RocketMq部署"></a>2、RocketMq部署</h2><h3 id="2-1、下载："><a href="#2-1、下载：" class="headerlink" title="2.1、下载："></a>2.1、下载：</h3><p><a href="http://rocketmq.apache.org/release_notes/release-notes-4.3.0/">http://rocketmq.apache.org/release_notes/release-notes-4.3.0/</a></p>
<p><a href="https://github.com/apache/rocketmq-externals.git">https://github.com/apache/rocketmq-externals.git</a></p>
<h3 id="2-2、解压release-notes-4-3-0后配置环境变量"><a href="#2-2、解压release-notes-4-3-0后配置环境变量" class="headerlink" title="2.2、解压release-notes-4.3.0后配置环境变量"></a>2.2、解压release-notes-4.3.0后配置环境变量</h3><a id="more"></a>

<p>变量名：ROCKETMQ_HOME<br>变量值：MQ解压路径\MQ文件夹名</p>
<p>如：ROCKETMQ_HOME =E:\rocketmq-all-4.3.0-bin-release</p>
<h3 id="2-3、启动NAMESERVER"><a href="#2-3、启动NAMESERVER" class="headerlink" title="2.3、启动NAMESERVER"></a>2.3、启动NAMESERVER</h3><p>Cmd命令框执行进入（release-notes-4.3.0）至‘MQ文件夹\bin’下，然后执行‘<strong>start mqnamesrv.cmd</strong>’，启动NAMESERVER。成功后会弹出提示框，此框勿关闭。</p>
<p><img src="/assets/resource/rocket/rocketmq2.png"></p>
<h3 id="2-4、启动BROKER"><a href="#2-4、启动BROKER" class="headerlink" title="2.4、启动BROKER"></a>2.4、启动BROKER</h3><p>Cmd命令框执行进入（release-notes-4.3.0）至‘MQ文件夹\bin’下，然后执行‘<strong>start mqbroker.cmd -n 127.0.0.1:9876 autoCreateTopicEnable=true</strong>’，启动BROKER。成功后会弹出提示框，此框勿关闭。</p>
<h2 id="3、RocketMQ插件部署解压rocketmq-externals"><a href="#3、RocketMQ插件部署解压rocketmq-externals" class="headerlink" title="3、RocketMQ插件部署解压rocketmq-externals"></a>3、RocketMQ插件部署解压rocketmq-externals</h2><p>下载完成之后，进入‘rocketmq-externals\rocketmq-console\src\main\resources’文件夹，打开‘application.properties’进行配置。</p>
<p><img src="/assets/resource/rocket/rocketmq3.png"></p>
<h3 id="3-1、编译并启动"><a href="#3-1、编译并启动" class="headerlink" title="3.1、编译并启动"></a>3.1、编译并启动</h3><p>用CMD进入‘\rocketmq-externals\rocketmq-console’文件夹，执行‘mvn clean package -Dmaven.test.skip=true’，编译生成。</p>
<p>编译成功之后，Cmd进入‘target’文件夹，执行‘java -jar rocketmq-console-ng 2.0.0.jar’，启动‘rocketmq-console-ng 2.0.0.jar’。</p>
<p>浏览器中输入‘127.0.0.1:配置端口’，成功后即可查看。</p>
<p><img src="/assets/resource/rocket/rocketmq1.png"></p>
]]></content>
      <tags>
        <tag>RocketMq</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper windows 安装 单机测试</title>
    <url>/2020/10/19/Zookeeper%20windows%20%E5%AE%89%E8%A3%85%20%E5%8D%95%E6%9C%BA/</url>
    <content><![CDATA[<h2 id="一、安装"><a href="#一、安装" class="headerlink" title="一、安装"></a>一、安装</h2><p>zookeeper 下载地址为: <a href="https://zookeeper.apache.org/releases.html">https://zookeeper.apache.org/releases.html</a></p>
<p>本例使用版本 zookeeper-3.4.14</p>
<p>1、查看 conf 目录下是否存在 zoo.cfg ，没有时将 zoo_sample.cfg 文件，复制一份，重命名为 zoo.cfg:</p>
<p><img src="/assets/resource/zookeeper/1.png"></p>
<a id="more"></a>

<p>2、在安装目录下面新建一个空的 data 文件夹和 log 文件夹:</p>
<p><img src="/assets/resource/zookeeper/2.png"></p>
<p>3、修改 zoo.cfg 配置文件，将 dataDir=/tmp/zookeeper 修改成 zookeeper 安装目录所在的 data 文件夹，再添加一条添加数据日志的配置(需要根据自己的安装路径修改)。</p>
<p><img src="/assets/resource/zookeeper/3.png"></p>
<p>4、双击 bin目录下zkServer.cmd 启动程序:控制台显示 <strong>bind to port 0.0.0.0/0.0.0.0:2181</strong>，表示服务端启动成功!</p>
<p><img src="/assets/resource/zookeeper/4.png"></p>
<p>5、双击 bin目录下zkCli.cmd 启动客户端</p>
<p><img src="/assets/resource/zookeeper/5.png"></p>
<h2 id="二、-Java连接测试"><a href="#二、-Java连接测试" class="headerlink" title="二、 Java连接测试"></a>二、 Java连接测试</h2><p>使用的 IDE 为 IntelliJ IDEA，创建一个 maven 工程，命名为 zookeeper-demo，并且引入如下依赖，可以自行在maven中央仓库选择合适的版本，介绍原生 API 和 Curator 两种方式。</p>
<p>1、依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;junit&lt;&#x2F;groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;junit&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;version&gt;4.11&lt;&#x2F;version&gt;</span><br><span class="line">  &lt;scope&gt;test&lt;&#x2F;scope&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.apache.zookeeper&lt;&#x2F;groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;zookeeper&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;version&gt;3.4.8&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.apache.curator&lt;&#x2F;groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;curator-framework&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;version&gt;4.0.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">  &lt;groupId&gt;org.apache.curator&lt;&#x2F;groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;curator-recipes&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;version&gt;4.0.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<p>2、客户端的 zookeeper 原生 API</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ConnectionDemo &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            final CountDownLatch countDownLatch &#x3D; new CountDownLatch(1);</span><br><span class="line">            ZooKeeper zooKeeper &#x3D;</span><br><span class="line">                    new ZooKeeper(&quot;127.0.0.1:2181&quot;,</span><br><span class="line">                            4000, new Watcher() &#123;</span><br><span class="line">                        @Override</span><br><span class="line">                        public void process(WatchedEvent event) &#123;</span><br><span class="line">                            if (Event.KeeperState.SyncConnected &#x3D;&#x3D; event.getState()) &#123;</span><br><span class="line">                                &#x2F;&#x2F;如果收到了服务端的响应事件，连接成功</span><br><span class="line">                                countDownLatch.countDown();</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;);</span><br><span class="line">            &#x2F;&#x2F; countDownLatch.await();</span><br><span class="line">            &#x2F;&#x2F;CONNECTED</span><br><span class="line">           &#x2F;&#x2F; zooKeeper.create(&quot;&#x2F;runoob&quot;,&quot;0&quot;.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">            System.out.println(zooKeeper.getState());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>控制台输出 connected 显示连接成功!</p>
<p>log4j:WARN No appenders could be found for logger (org.apache.zookeeper.ZooKeeper).<br>log4j:WARN Please initialize the log4j system properly.<br>log4j:WARN See <a href="http://logging.apache.org/log4j/1.2/faq.html#noconfig">http://logging.apache.org/log4j/1.2/faq.html#noconfig</a> for more info.<br>CONNECTED</p>
<p>Process finished with exit code 0</p>
<p>简单示例添加节点 API，将上述代码中</p>
<p> zooKeeper.create(“/runoob”,”0”.getBytes(),ZooDefs.Ids.OPEN_ACL_UNSAFE,CreateMode.PERSISTENT);</p>
<p>注释打开执行，同时在服务端终端执行命令，显示设置成功。</p>
<p>[zk: localhost:2181(CONNECTED) 1] get /runoob<br>0<br>cZxid = 0x69<br>ctime = Fri Oct 16 15:51:26 GMT+08:00 2020<br>mZxid = 0x69<br>mtime = Fri Oct 16 15:51:26 GMT+08:00 2020<br>pZxid = 0x69<br>cversion = 0<br>dataVersion = 0<br>aclVersion = 0<br>ephemeralOwner = 0x0<br>dataLength = 1<br>numChildren = 0<br>[zk: localhost:2181(CONNECTED) 2]</p>
<p>3、客户端的curator连接</p>
<p>Curator 是 Netflix 公司开源的一套 zookeeper 客户端框架，解决了很多 Zookeeper 客户端非常底层的细节开发工作，包括连接重连、反复注册 Watcher 和 NodeExistsException 异常等。</p>
<p>Curator 包含了几个包：</p>
<ul>
<li><p><strong>curator-framework</strong>：对 zookeeper 的底层 api 的一些封装。</p>
</li>
<li><p><strong>curator-client</strong>：提供一些客户端的操作，例如重试策略等。</p>
</li>
<li><p><strong>curator-recipes</strong>：封装了一些高级特性，如：Cache 事件监听、选举、分布式锁、分布式计数器、分布式 Barrier 等。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class CuratorDemo &#123;</span><br><span class="line">    public static void main(String[] args) throws Exception &#123;</span><br><span class="line">        CuratorFramework curatorFramework&#x3D; CuratorFrameworkFactory.</span><br><span class="line">                builder().connectString(&quot;127.0.0.1:2181&quot;).</span><br><span class="line">                sessionTimeoutMs(4000).retryPolicy(new</span><br><span class="line">                ExponentialBackoffRetry(1000,3)).</span><br><span class="line">                namespace(&quot;&quot;).build();</span><br><span class="line">        curatorFramework.start();</span><br><span class="line">        Stat stat&#x3D;new Stat();</span><br><span class="line">        &#x2F;&#x2F;查询节点数据</span><br><span class="line">        byte[] bytes &#x3D;        curatorFramework.getData().storingStatIn(stat).forPath(&quot;&#x2F;runoob&quot;);</span><br><span class="line">        System.out.println(new String(bytes));</span><br><span class="line">        curatorFramework.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>上一步设置了 <strong>/runoob</strong> 节点值，所以控制台输出。</p>
<p>log4j:WARN No appenders could be found for logger (org.apache.curator.utils.Compatibility).<br>log4j:WARN Please initialize the log4j system properly.<br>log4j:WARN See <a href="http://logging.apache.org/log4j/1.2/faq.html#noconfig">http://logging.apache.org/log4j/1.2/faq.html#noconfig</a> for more info.<br>0</p>
<p>Process finished with exit code 0</p>
]]></content>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop之MapReduce</title>
    <url>/2020/09/25/hadoop%E4%B9%8BMapReduce/</url>
    <content><![CDATA[<h2 id="MapReduce简介"><a href="#MapReduce简介" class="headerlink" title="MapReduce简介"></a>MapReduce简介</h2><p>MapReduce <strong>（分布式计算框架）</strong>是一种基于磁盘的分布式并行批处理计算模型，用于处理大数据量的计算。其中Map对应数据集上的独立元素进行指定的操作，生成键-值对形式中间，Reduce则对中间结果中相同的键的所有值进行规约，以得到最终结果。</p>
<p>Jobtracker：master节点，只有一个，管理所有作业，任务/作业的监控，错误处理等，将任务分解成一系列任务，并分派给Tasktracker。</p>
<p>Tacktracker：slave节点，运行 Map task和Reduce task；并与Jobtracker交互，汇报任务状态。</p>
<p>Map task：解析每条数据记录，传递给用户编写的map()函数并执行，将输出结果写入到本地磁盘（如果为map—only作业，则直接写入HDFS）。</p>
<p>Reduce task：从Map 它深刻地执行结果中，远程读取输入数据，对数据进行排序，将数据分组传递给用户编写的Reduce()函数执行。</p>
<a id="more"></a>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.hadoop&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hadoop-common&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.8.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.hadoop&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hadoop-hdfs&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.8.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.liujl.mapreduce.util;</span><br><span class="line">import org.apache.hadoop.io.IntWritable;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @Author: Administrator</span><br><span class="line"> * @Description:</span><br><span class="line"> * @Date: 2020&#x2F;9&#x2F;23 0023 16:18</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 四个泛型类型分别代表：</span><br><span class="line">     * KeyIn        Mapper的输入数据的Key，这里是每行文字的起始位置（0,11,...）</span><br><span class="line">     * ValueIn      Mapper的输入数据的Value，这里是每行文字</span><br><span class="line">     * KeyOut       Mapper的输出数据的Key，这里是每行文字中的“年份”</span><br><span class="line">     * ValueOut     Mapper的输出数据的Value，这里是每行文字中的“气温”</span><br><span class="line">     *&#x2F;</span><br><span class="line">    @Override</span><br><span class="line">    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        String line &#x3D; value.toString();</span><br><span class="line">        String year &#x3D; line.substring(0, 4);</span><br><span class="line">        int temperature &#x3D; Integer.parseInt(line.substring(8));</span><br><span class="line">        context.write(new Text(year), new IntWritable(temperature));</span><br><span class="line">        &#x2F;&#x2F; 打印样本: After Mapper:2000, 15</span><br><span class="line">        System.out.println(&quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; + &quot;After Mapper:&quot; + new Text(year) + &quot;, &quot; + new IntWritable(temperature));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.liujl.mapreduce.util;</span><br><span class="line">import org.apache.hadoop.io.IntWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * @Author: Administrator</span><br><span class="line"> * @Description:</span><br><span class="line"> * @Date: 2020&#x2F;9&#x2F;23 0023 16:30</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class MyReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line">    @Override</span><br><span class="line">    public void reduce(Text key, Iterable&lt;IntWritable&gt; values,</span><br><span class="line">                       Context context) throws IOException, InterruptedException &#123;</span><br><span class="line">        int maxValue &#x3D; Integer.MIN_VALUE;</span><br><span class="line">        StringBuffer sb &#x3D; new StringBuffer();</span><br><span class="line">        &#x2F;&#x2F;取values的最大值</span><br><span class="line">        for (IntWritable value : values) &#123;</span><br><span class="line">            maxValue &#x3D; Math.max(maxValue, value.get());</span><br><span class="line">            sb.append(value).append(&quot;, &quot;);</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F; 打印样本： Before Reduce: 2000, 15, 23, 99, 12, 22,</span><br><span class="line">        System.out.print(&quot;Before Reduce: &quot; + key + &quot;, &quot; + sb.toString());</span><br><span class="line">        context.write(key, new IntWritable(maxValue));</span><br><span class="line">        &#x2F;&#x2F; 打印样本： After Reduce: 2000, 99</span><br><span class="line">        System.out.println(&quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; + &quot;After Reduce: &quot; + key + &quot;, &quot; + maxValue);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">package com.liujl.mapreduce;</span><br><span class="line"></span><br><span class="line">import com.liujl.mapreduce.util.MyMapper;</span><br><span class="line">import com.liujl.mapreduce.util.MyReducer;</span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.FileSystem;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.IntWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line">import org.junit.jupiter.api.Test;</span><br><span class="line">import org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">@SpringBootTest</span><br><span class="line">class MapreduceApplicationTests &#123;</span><br><span class="line"></span><br><span class="line">    @Test</span><br><span class="line">    void contextLoads() throws IOException, ClassNotFoundException, InterruptedException &#123;</span><br><span class="line">        &#x2F;&#x2F;输入路径</span><br><span class="line">        String dst &#x3D; &quot;hdfs:&#x2F;&#x2F;localhost:9500&#x2F;user&#x2F;wcinput&#x2F;mapreduce.txt&quot;;</span><br><span class="line">        &#x2F;&#x2F;输出路径，必须是不存在的，空文件夹也不行。</span><br><span class="line"></span><br><span class="line">        Configuration hadoopConfig &#x3D; new Configuration();</span><br><span class="line">        System.setProperty(&quot;hadoop.home.dir&quot;, &quot;E:\\hadoop-3.0.0&quot;);</span><br><span class="line">        hadoopConfig.set(&quot;fs.hdfs.impl&quot;,</span><br><span class="line">                org.apache.hadoop.hdfs.DistributedFileSystem.class.getName()</span><br><span class="line">        );</span><br><span class="line">        hadoopConfig.set(&quot;fs.file.impl&quot;,</span><br><span class="line">                org.apache.hadoop.fs.LocalFileSystem.class.getName()</span><br><span class="line">        );</span><br><span class="line">        String tempPath&#x3D;&quot;&#x2F;&quot;+System.currentTimeMillis()+&quot;&quot;;</span><br><span class="line">        String dstOut &#x3D; &quot;hdfs:&#x2F;&#x2F;localhost:9500&#x2F;user&#x2F;wcinput&quot;+tempPath;</span><br><span class="line">        Job job &#x3D; new Job(hadoopConfig);</span><br><span class="line">        &#x2F;&#x2F;如果需要打成jar运行，需要下面这句</span><br><span class="line">        &#x2F;&#x2F;job.setJarByClass(NewMaxTemperature.class);</span><br><span class="line">        &#x2F;&#x2F;job执行作业时输入和输出文件的路径</span><br><span class="line">        FileInputFormat.addInputPath(job, new Path(dst));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, new Path(dstOut));</span><br><span class="line">        &#x2F;&#x2F;指定自定义的Mapper和Reducer作为两个阶段的任务处理类</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        &#x2F;&#x2F;设置最后输出结果的Key和Value的类型</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line">        &#x2F;&#x2F;执行job，直到完成</span><br><span class="line">        job.waitForCompletion(true);</span><br><span class="line">        System.out.println(&quot;Finished&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>2014010114<br>2014010216<br>2014010317<br>2014010410<br>2014010506<br>2012010609<br>2012010732<br>2012010812<br>2012010919<br>2012011023<br>2001010116<br>2001010212<br>2001010310<br>2001010411<br>2001010529<br>2013010619<br>2013010722<br>2013010812<br>2013010929<br>2013011023<br>2008010105<br>2008010216<br>2008010337<br>2008010414<br>2008010516<br>2007010619<br>2007010712<br>2007010812<br>2007010999<br>2007011023<br>2010010114<br>2010010216<br>2010010317<br>2010010410<br>2010010506<br>2015010649<br>2015010722<br>2015010812<br>2015010999<br>2015011023</p>
</blockquote>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>hadoop常用操作命令汇总</title>
    <url>/2020/09/25/hadoop%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/</url>
    <content><![CDATA[<h2 id="hadoop常用操作命令汇总"><a href="#hadoop常用操作命令汇总" class="headerlink" title="hadoop常用操作命令汇总"></a>hadoop常用操作命令汇总</h2><p>（1）、列出根目录下所有的目录或文件</p>
<blockquote>
<p>hadoop dfs -ls /</p>
</blockquote>
<p>（2）、列出/user目录下的所有目录和文件</p>
<blockquote>
<p>Hadoop  dfs  -ls  /user</p>
</blockquote>
<p>（3）、列出/user目录及其子目录下的所有文件（谨慎使用） </p>
<blockquote>
<p>hadoop dfs -ls -R /user</p>
</blockquote>
<p>（4）、创建/soft目录</p>
<blockquote>
<p>hadoop dfs -mkdir /soft</p>
</blockquote>
<a id="more"></a>

<p>（5）、创建多级目录</p>
<blockquote>
<p>hadoop dfs -mkdir -p /apps/windows/2017/01/01</p>
</blockquote>
<p>（6）、将本地的wordcount.jar文件上传到/wordcount目录下</p>
<blockquote>
<p>hadoop dfs -put wordcount.jar /wordcount</p>
</blockquote>
<p>（7）、下载words.txt文件到本地</p>
<blockquote>
<p>hadoop dfs -get /words.txt </p>
</blockquote>
<p>（8）、将/stu/students.txt文件拷贝到本地</p>
<blockquote>
<p>hadoop dfs -copyToLocal /stu/students.txt</p>
</blockquote>
<p>（9）、将word.txt文件拷贝到/wordcount/input/目录</p>
<blockquote>
<p>hadoop dfs -copyFromLocal word.txt /wordcount/input </p>
</blockquote>
<p>（10）、将word.txt文件从本地移动到/wordcount/input/目录下</p>
<blockquote>
<p>hadoop dfs -moveFromLocal word.txt /wordcount/input/</p>
</blockquote>
<p>（11）、将/stu/students.txt拷贝一份为/stu/students.txt.bak</p>
<blockquote>
<p>hadoop dfs -cp /stu/student.txt /stu/students.txt.bak </p>
</blockquote>
<p>（12）、将/flume/tailout/目录下的子目录或文件都拷贝到/logs目录（如果此目录不存在会创建）下</p>
<blockquote>
<p> hadoop dfs -cp /flume/tailout/ /logs </p>
</blockquote>
<p>（13）、将/word.txt文件重命名为/words.txt</p>
<blockquote>
<p>hadoop dfs -mv /word.txt /words.txt</p>
</blockquote>
<p>（14）、将/words.txt文件移动到/wordcount/input/目录下</p>
<blockquote>
<p>hadoop dfs -mv /words.txt /wordcount/input/</p>
</blockquote>
<p>（15）、将/ws目录以及子目录和文件都删除（谨慎使用）</p>
<blockquote>
<p>hadoop dfs -rm -r /ws </p>
</blockquote>
<p>（16）、删除以”xbs-“开头的目录及其子目录</p>
<blockquote>
<p>hadoop dfs -rm -r /xbs-*</p>
</blockquote>
<p>（17）、将/wordcount/output2/目录下的a.txt文件删除</p>
<blockquote>
<p>hadoop dfs -rm /wordcount/output2/a.txt </p>
</blockquote>
<p>（18）、将/wordcount/input/目录下面的所有文件都删除</p>
<blockquote>
<p>hadoop dfs -rm /wordcount/input/*</p>
</blockquote>
<p>（19）、查看HDFS集群的磁盘空间使用情况</p>
<blockquote>
<p>hadoop dfs -df -h </p>
</blockquote>
<p>（20）、查看/word.txt文件的内容</p>
<blockquote>
<p>hadoop dfs -cat /word.txt </p>
</blockquote>
<p>（21）、将name.txt文件中的内容添加到/wordcount/input/words.txt文件中</p>
<blockquote>
<p>hadoop dfs -appendToFile name.txt /wordcount/input/words.txt</p>
</blockquote>
<p>（22）、动态查看/wordcount/input/words.txt文件的内容</p>
<blockquote>
<p>hadoop dfs -tail -f /wordcount/input/words.txt</p>
</blockquote>
<p>（23）、统计/flume目录总大小</p>
<blockquote>
<p>hadoop dfs -du -s -h /flume</p>
</blockquote>
<p>（24）、分别统计/flume目录下各个子目录（或文件）大小</p>
<blockquote>
<p>hadoop dfs -du -s -h /flume/*</p>
</blockquote>
<p>（25）、运行jar包中的程序</p>
<p>//hadoop jar + 要执行的jar包 + 要运行的类 + 输入目录 + 输出目录</p>
<blockquote>
<p>hadoop jar wordcount.jar com.xuebusi.hadoop.mr.WordCountDriver /wordcount/input /wordcount/out</p>
</blockquote>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo 命令</title>
    <url>/2020/08/22/hexo%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<a id="more"></a>

<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <tags>
        <tag>hexo</tag>
        <tag>yilia</tag>
      </tags>
  </entry>
  <entry>
    <title>redis 基本操作</title>
    <url>/2020/08/29/redis%20%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<ul>
<li>redis是key-value的数据结构，每条数据都是⼀个键值对</li>
<li>键的类型是字符串</li>
<li>注意：键不能重复</li>
<li>值的类型分为五种：</li>
<li>字符串string</li>
<li>哈希hash</li>
<li>列表list</li>
<li>集合set</li>
<li>有序集合zset<a id="more"></a></li>
<li>string类型</li>
<li>字符串类型是 Redis 中最为基础的数据存储类型，它在 Redis 中是二进制安全的，这便意味着该类型可以接受任何格式的数据，如JPEG图像数据或Json对象描述信息等。在Redis中字符串类型的Value最多可以容纳的数据长度是512M。</li>
</ul>
<ul>
<li>设置键值</li>
</ul>
<p>set key value</p>
<ul>
<li>例1：设置键为name值为itcast的数据</li>
</ul>
<p>set name itcast</p>
<ul>
<li>设置键值及过期时间，以秒为单位</li>
</ul>
<p>setex key seconds value</p>
<ul>
<li>例2：设置键为aa值为aa过期时间为3秒的数据</li>
</ul>
<p>setex aa 3 aa</p>
<ul>
<li>设置多个键值</li>
</ul>
<p>mset key1 value1 key2 value2 …</p>
<ul>
<li>例3：设置键为’a1’值为’python’、键为’a2’值为’java’、键为’a3’值为’c’</li>
</ul>
<p>mset a1 python a2 java a3 c</p>
<ul>
<li>追加值</li>
</ul>
<p>append key value</p>
<ul>
<li>例4：向键为a1中追加值’ haha’</li>
</ul>
<p>append ‘a1’ ‘haha’</p>
<h1 id="获取"><a href="#获取" class="headerlink" title="获取"></a><strong>获取</strong></h1><ul>
<li>获取：根据键获取值，如果不存在此键则返回null</li>
</ul>
<p>get key</p>
<ul>
<li>例5：获取键’name’的值</li>
</ul>
<p>get ‘name’</p>
<ul>
<li>根据多个键获取多个值</li>
</ul>
<p>mget key1 key2 …</p>
<ul>
<li>例6：获取键a1、a2、a3’的值</li>
</ul>
<p>mget a1 a2 a3</p>
<ul>
<li>查看键对应的value的类型</li>
</ul>
<p>type key</p>
<ul>
<li>例4：查看键a1的值类型，为redis⽀持的五种类型中的⼀种</li>
</ul>
<p>type a1</p>
<ul>
<li>删除键及对应的值</li>
</ul>
<p>del key1 key2 …</p>
<ul>
<li>例5：删除键a2、a3</li>
</ul>
<p>del a2 a3</p>
<ul>
<li>设置过期时间，以秒为单位</li>
<li>如果没有指定过期时间则⼀直存在，直到使⽤DEL移除</li>
</ul>
<p>expire key seconds</p>
<ul>
<li>例6：设置键’a1’的过期时间为3秒</li>
</ul>
<p>expire ‘a1’ 3</p>
<p>查看有效时间，以秒为单位</p>
<p>ttl key</p>
<h1 id="hash类型"><a href="#hash类型" class="headerlink" title="hash类型"></a><strong>hash类型</strong></h1><ul>
<li>hash⽤于存储对象，对象的结构为属性、值</li>
<li>值的类型为string</li>
<li>设置单个属性</li>
</ul>
<h2 id="增加、修改"><a href="#增加、修改" class="headerlink" title="增加、修改"></a><strong>增加、修改</strong></h2><p>hset key field value</p>
<ul>
<li>例1：设置键 user的属性name为itheima</li>
</ul>
<p>hset user name itheima</p>
<p>MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. Commands that may modify the data set are disabled. Please check Redis logs for details about the error.</p>
<p>Redis被配置为保存数据库快照，但它目前不能持久化到硬盘。用来修改集合数据的命令不能用</p>
<p>原因：</p>
<ul>
<li>强制关闭Redis快照导致不能持久化。 解决方案：</li>
<li>运行config set stop-writes-on-bgsave-error no　命令后，关闭配置项stop-writes-on-bgsave-error解决该问题。</li>
<li>设置多个属性</li>
</ul>
<p>hmset key field1 value1 field2 value2 …</p>
<ul>
<li>例2：设置键u2的属性name为itcast、属性age为11</li>
</ul>
<p>hmset u2 name itcast age 11</p>
<h2 id="获取-1"><a href="#获取-1" class="headerlink" title="获取"></a><strong>获取</strong></h2><ul>
<li>获取指定键所有的属性</li>
</ul>
<p>hkeys key</p>
<ul>
<li>例3：获取键u2的所有属性</li>
</ul>
<p>hkeys u2</p>
<ul>
<li>获取⼀个属性的值</li>
</ul>
<p>hget key field</p>
<ul>
<li>例4：获取键u2属性’name’的值</li>
</ul>
<p>hget u2 ‘name’</p>
<ul>
<li>获取多个属性的值</li>
</ul>
<p>hmget key field1 field2 …</p>
<ul>
<li>例5：获取键u2属性’name’、’age的值</li>
</ul>
<p>hmget u2 name age</p>
<ul>
<li>获取所有属性的值</li>
</ul>
<p>hvals key</p>
<ul>
<li>例6：获取键’u2’所有属性的值</li>
</ul>
<p>hvals u2</p>
<h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a><strong>删除</strong></h2><ul>
<li>删除整个hash键及值，使⽤del命令</li>
<li>删除属性，属性对应的值会被⼀起删除</li>
</ul>
<p>hdel key field1 field2 …</p>
<ul>
<li>例7：删除键’u2’的属性’age’</li>
</ul>
<p>hdel u2 age</p>
<h1 id="list类型"><a href="#list类型" class="headerlink" title="list类型"></a><strong>list类型</strong></h1><ul>
<li>列表的元素类型为string</li>
<li>按照插⼊顺序排序</li>
<li>在左侧插⼊数据</li>
</ul>
<h2 id="增加"><a href="#增加" class="headerlink" title="增加"></a><strong>增加</strong></h2><p>lpush key value1 value2 …</p>
<ul>
<li>例1：从键为’a1’的列表左侧加⼊数据a 、 b 、c</li>
</ul>
<p>lpush a1 a b c</p>
<ul>
<li>在右侧插⼊数据</li>
</ul>
<p>rpush key value1 value2 …</p>
<ul>
<li>例2：从键为’a1’的列表右侧加⼊数据0 1</li>
</ul>
<p>rpush a1 0 1</p>
<ul>
<li>在指定元素的前或后插⼊新元素</li>
</ul>
<p>linsert key before或after 现有元素 新元素</p>
<ul>
<li>例3：在键为’a1’的列表中元素’b’前加⼊’3’</li>
</ul>
<p>linsert a1 before b 3</p>
<h2 id="获取-2"><a href="#获取-2" class="headerlink" title="获取"></a><strong>获取</strong></h2><ul>
<li>返回列表⾥指定范围内的元素</li>
<li>start、stop为元素的下标索引</li>
<li>索引从左侧开始，第⼀个元素为0</li>
<li>索引可以是负数，表示从尾部开始计数，如-1表示最后⼀个元素</li>
</ul>
<p>lrange key start stop</p>
<ul>
<li>例4：获取键为’a1’的列表所有元素</li>
</ul>
<p>lrange a1 0 -1</p>
<h2 id="设置指定索引位置的元素值"><a href="#设置指定索引位置的元素值" class="headerlink" title="设置指定索引位置的元素值"></a><strong>设置指定索引位置的元素值</strong></h2><ul>
<li>索引从左侧开始，第⼀个元素为0</li>
<li>索引可以是负数，表示尾部开始计数，如-1表示最后⼀个元素</li>
</ul>
<p>lset key index value</p>
<ul>
<li>例5：修改键为’a1’的列表中下标为1的元素值为’z’</li>
</ul>
<p>lset a 1 z</p>
<h2 id="删除-1"><a href="#删除-1" class="headerlink" title="删除"></a><strong>删除</strong></h2><ul>
<li>删除指定元素</li>
<li>将列表中前count次出现的值为value的元素移除</li>
<li>count &gt; 0: 从头往尾移除</li>
<li>count &lt; 0: 从尾往头移除</li>
<li>count = 0: 移除所有</li>
</ul>
<p>lrem key count value</p>
<ul>
<li>例6.1：向列表’a2’中加⼊元素’a’、’b’、’a’、’b’、’a’、’b’</li>
</ul>
<p>lpush a2 a b a b a b</p>
<ul>
<li>例6.2：从’a2’列表右侧开始删除2个’b’</li>
</ul>
<p>lrem a2 -2 b</p>
<ul>
<li>例6.3：查看列表’py12’的所有元素</li>
</ul>
<p>lrange a2 0 -1</p>
<h1 id="set类型"><a href="#set类型" class="headerlink" title="set类型"></a><strong>set类型</strong></h1><ul>
<li>⽆序集合</li>
<li>元素为string类型</li>
<li>元素具有唯⼀性，不重复</li>
<li>说明：对于集合没有修改操作</li>
<li>添加元素</li>
</ul>
<h2 id="增加-1"><a href="#增加-1" class="headerlink" title="增加"></a><strong>增加</strong></h2><p>sadd key member1 member2 …</p>
<ul>
<li>例1：向键’a3’的集合中添加元素’zhangsan’、’lisi’、’wangwu’</li>
</ul>
<p>sadd a3 zhangsan sili wangwu</p>
<h2 id="获取-3"><a href="#获取-3" class="headerlink" title="获取"></a><strong>获取</strong></h2><ul>
<li>返回所有的元素</li>
</ul>
<p>smembers key</p>
<ul>
<li>例2：获取键’a3’的集合中所有元素</li>
</ul>
<p>smembers a3</p>
<h2 id="删除-2"><a href="#删除-2" class="headerlink" title="删除"></a><strong>删除</strong></h2><ul>
<li>删除指定元素</li>
</ul>
<p>srem key</p>
<ul>
<li>例3：删除键’a3’的集合中元素’wangwu’</li>
</ul>
<p>srem a3 wangwu</p>
<h1 id="zset类型"><a href="#zset类型" class="headerlink" title="zset类型"></a><strong>zset类型</strong></h1><ul>
<li>sorted set，有序集合</li>
<li>元素为string类型</li>
<li>元素具有唯⼀性，不重复</li>
<li>每个元素都会关联⼀个double类型的score，表示权重，通过权重将元素从⼩到⼤排序</li>
<li>说明：没有修改操作</li>
<li>添加</li>
</ul>
<h2 id="增加-2"><a href="#增加-2" class="headerlink" title="增加"></a><strong>增加</strong></h2><p>zadd key score1 member1 score2 member2 …</p>
<ul>
<li>例1：向键’a4’的集合中添加元素’lisi’、’wangwu’、’zhaoliu’、’zhangsan’，权重分别为4、5、6、3</li>
</ul>
<p>zadd a4 4 lisi 5 wangwu 6 zhaoliu 3 zhangsan</p>
<h2 id="获取-4"><a href="#获取-4" class="headerlink" title="获取"></a><strong>获取</strong></h2><ul>
<li>返回指定范围内的元素</li>
<li>start、stop为元素的下标索引</li>
<li>索引从左侧开始，第⼀个元素为0</li>
<li>索引可以是负数，表示从尾部开始计数，如-1表示最后⼀个元素</li>
</ul>
<p>zrange key start stop</p>
<ul>
<li>例2：获取键’a4’的集合中所有元素</li>
</ul>
<p>zrange a4 0 -1</p>
<ul>
<li>返回score值在min和max之间的成员</li>
</ul>
<p>zrangebyscore key min max</p>
<ul>
<li>例3：获取键’a4’的集合中权限值在5和6之间的成员</li>
</ul>
<p>zrangebyscore a4 5 6</p>
<ul>
<li>返回成员member的score值</li>
</ul>
<p>zscore key member</p>
<ul>
<li>例4：获取键’a4’的集合中元素’zhangsan’的权重</li>
</ul>
<p>zscore a4 zhangsan</p>
<h2 id="删除-3"><a href="#删除-3" class="headerlink" title="删除"></a><strong>删除</strong></h2><ul>
<li>删除指定元素</li>
</ul>
<p>zrem key member1 member2 …</p>
<ul>
<li>例5：删除集合’a4’中元素’zhangsan’</li>
</ul>
<p>zrem a4 zhangsan</p>
<ul>
<li>删除权重在指定范围的元素</li>
</ul>
<p>zremrangebyscore key min max</p>
<ul>
<li>例6：删除集合’a4’中权限在5、6之间的元素</li>
</ul>
<p>zremrangebyscore a4 5 6</p>
]]></content>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud之Zuul</title>
    <url>/2020/09/18/springcloud%20%E4%B9%8Bzuul/</url>
    <content><![CDATA[<h2 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h2><p>Zuul是Netflix开源的微服务网关，可以和Eureka、Ribbon、Hystrix等组件配合使用，Spring Cloud对Zuul进行了整合与增强，Zuul默认使用的HTTP客户端是Apache HTTPClient，也可以使用RestClient或okhttp3.OkHttpClient。  Zuul的主要功能是路由转发和过滤器。路由功能是微服务的一部分。zuul默认和Ribbon结合实现了负载均衡的功能</p>
<a id="more"></a>
<h2 id="2、贴代码"><a href="#2、贴代码" class="headerlink" title="2、贴代码"></a>2、贴代码</h2><p>（1）、pom依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;properties&gt;</span><br><span class="line">    &lt;project.build.sourceEncoding&gt;UTF-8&lt;&#x2F;project.build.sourceEncoding&gt;</span><br><span class="line">    &lt;project.reporting.outputEncoding&gt;UTF-8&lt;&#x2F;project.reporting.outputEncoding&gt;</span><br><span class="line">    &lt;java.version&gt;1.8&lt;&#x2F;java.version&gt;</span><br><span class="line">    &lt;spring-cloud.version&gt;Finchley.SR2&lt;&#x2F;spring-cloud.version&gt;</span><br><span class="line">&lt;&#x2F;properties&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependencies&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-cloud-starter-eureka&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.4.0.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;!-- 配置hystrix所需依赖的包 --&gt;</span><br><span class="line">    &lt;dependency&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;version&gt;1.4.7.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">    &lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;&#x2F;dependencies&gt;</span><br><span class="line">&lt;dependencyManagement&gt;</span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-cloud-dependencies&lt;&#x2F;artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;&#x2F;version&gt;</span><br><span class="line">            &lt;type&gt;pom&lt;&#x2F;type&gt;</span><br><span class="line">            &lt;scope&gt;import&lt;&#x2F;scope&gt;</span><br><span class="line">        &lt;&#x2F;dependency&gt;</span><br><span class="line">    &lt;&#x2F;dependencies&gt;</span><br><span class="line">&lt;&#x2F;dependencyManagement&gt;</span><br></pre></td></tr></table></figure>

<p>（2）、application.properties</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spring.application.name&#x3D;springbootZuul</span><br><span class="line">server.port&#x3D;6005</span><br><span class="line">eureka.client.service-url.defaultZone&#x3D;http:&#x2F;&#x2F;localhost:5000&#x2F;eureka&#x2F;</span><br><span class="line"></span><br><span class="line">zuul.routes.springbootService.path&#x3D;&#x2F;springbootService&#x2F;**</span><br><span class="line">zuul.routes.springbootService.serviceId&#x3D;springbootService</span><br><span class="line"></span><br><span class="line">zuul.routes.springCloudFeign.path&#x3D;&#x2F;springCloudFeign&#x2F;**</span><br><span class="line">zuul.routes.springCloudFeign.serviceId&#x3D;springCloudFeign</span><br></pre></td></tr></table></figure>

<p>（3）、主方法入口</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@SpringBootApplication</span><br><span class="line">@EnableDiscoveryClient</span><br><span class="line">@EnableZuulProxy</span><br><span class="line">@RefreshScope</span><br><span class="line">public class ZuulserviceApplication &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SpringApplication.run(ZuulserviceApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）、请求过滤</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class serviceFilter extends ZuulFilter &#123;</span><br><span class="line"></span><br><span class="line">    private static Logger log &#x3D; LoggerFactory.getLogger(serviceFilter.class);</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String filterType() &#123;</span><br><span class="line">        return &quot;pre&quot;; &#x2F;&#x2F; 定义filter的类型，有pre、route、post、error四种</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public int filterOrder() &#123;</span><br><span class="line">        return 0; &#x2F;&#x2F; 定义filter的顺序，数字越小表示顺序越高，越先执行</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public boolean shouldFilter() &#123;</span><br><span class="line">        return true; &#x2F;&#x2F; 表示是否需要执行该filter，true表示执行，false表示不执行</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Object run() &#123;</span><br><span class="line">        &#x2F;&#x2F; filter需要执行的具体操作</span><br><span class="line">        RequestContext ctx &#x3D; RequestContext.getCurrentContext();</span><br><span class="line">        HttpServletRequest request &#x3D; ctx.getRequest();</span><br><span class="line">        String token &#x3D; request.getParameter(&quot;token&quot;);</span><br><span class="line">        System.out.println(token);</span><br><span class="line">        if (token &#x3D;&#x3D; null) &#123;</span><br><span class="line">            log.warn(&quot;there is no request token&quot;);</span><br><span class="line">            ctx.setSendZuulResponse(false);</span><br><span class="line">            ctx.setResponseStatusCode(401);</span><br><span class="line">            try &#123;</span><br><span class="line">                ctx.getResponse().getWriter().write(&quot;there is no request token&quot;);</span><br><span class="line">            &#125; catch (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            return null;</span><br><span class="line">        &#125;</span><br><span class="line">        log.info(&quot;ok&quot;);</span><br><span class="line">        return null;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（5）、失败回调</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class ServiceFallbackProvider implements FallbackProvider &#123;</span><br><span class="line">    @Override</span><br><span class="line">    &#x2F;&#x2F; 指定熔断器功能应用于哪些路由的服务</span><br><span class="line">    public String getRoute() &#123;</span><br><span class="line">        &#x2F;&#x2F; 这里只针对&quot;springbootService&quot;服务进行熔断</span><br><span class="line">        &#x2F;&#x2F; 如果需要针对所有服务熔断，则return &quot;*&quot;</span><br><span class="line">        return &quot;springbootService&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public ClientHttpResponse fallbackResponse(String route, Throwable cause) &#123;</span><br><span class="line">        System.out.println(&quot;route:&quot;+route);</span><br><span class="line"></span><br><span class="line">        return new ClientHttpResponse() &#123;</span><br><span class="line">            @Override</span><br><span class="line">            public HttpStatus getStatusCode() throws IOException &#123;</span><br><span class="line">                return HttpStatus.OK;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public int getRawStatusCode() throws IOException &#123;</span><br><span class="line">                return 200;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public String getStatusText() throws IOException &#123;</span><br><span class="line">                return &quot;ok&quot;;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public void close() &#123;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            &#x2F;&#x2F; 发生熔断式，返回的信息</span><br><span class="line">            public InputStream getBody() throws IOException &#123;</span><br><span class="line">                return new ByteArrayInputStream(&quot;Sorry, the service is unavailable now.&quot;.getBytes());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            @Override</span><br><span class="line">            public HttpHeaders getHeaders() &#123;</span><br><span class="line">                HttpHeaders headers &#x3D; new HttpHeaders();</span><br><span class="line">                headers.setContentType(MediaType.APPLICATION_JSON);</span><br><span class="line">                return headers;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Zuul</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud之生产者</title>
    <url>/2020/09/18/springcloud%20%E4%B9%8B%E7%94%9F%E4%BA%A7%E8%80%85/</url>
    <content><![CDATA[<h2 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h2><p>生产者为了提供测试方法</p>
<h2 id="2、贴代码"><a href="#2、贴代码" class="headerlink" title="2、贴代码"></a>2、贴代码</h2><p>（1）、application.properties文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spring.application.name&#x3D;springbootService</span><br><span class="line"></span><br><span class="line">server.port&#x3D;6001</span><br><span class="line"></span><br><span class="line">eureka.client.service-url.defaultZone&#x3D;http:&#x2F;&#x2F;user1:password1@localhost:5000&#x2F;eureka&#x2F;</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>（2）、pom依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.commons&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;commons-lang3&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.4&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;fastjson&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.2.7&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.fasterxml.jackson.module&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;jackson-module-jaxb-annotations&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.0.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--Spring Cloud Config 客户端依赖--&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-config&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.0.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--Spring Boot Actuator，感应服务端变化--&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-actuator&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<p>（3）、主入口方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@SpringBootApplication</span><br><span class="line">@ServletComponentScan</span><br><span class="line">@EnableDiscoveryClient</span><br><span class="line">@RefreshScope</span><br><span class="line">public class ProductserviceApplication &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SpringApplication.run(ProductserviceApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）、返回Dto实体类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class RestfulResult &#123;</span><br><span class="line"></span><br><span class="line">    private String result &#x3D; &quot;Success&quot;;</span><br><span class="line">    private String message;</span><br><span class="line">    private Object data;      &#x2F;&#x2F; 返回数据</span><br><span class="line">    private int cntPage;      &#x2F;&#x2F; page数</span><br><span class="line">    private long cntData;     &#x2F;</span><br></pre></td></tr></table></figure>

<p>（5）、实体</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class ServiceInfo implements Serializable &#123;</span><br><span class="line">    private static final long serialVersionUID &#x3D; 5321862855702089487L;</span><br><span class="line"></span><br><span class="line">    private String name;</span><br><span class="line"></span><br><span class="line">    public String getName() &#123;</span><br><span class="line">        return name;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public ServiceInfo() &#123;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（6）、工具类</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class CommUtils &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; JSON格式化</span><br><span class="line">    public static String printDataJason(HttpServletResponse response,</span><br><span class="line">                                        Object item) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line"></span><br><span class="line">            JsonUtils.renderString(response, item);</span><br><span class="line"></span><br><span class="line">        &#125; catch (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return null;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 随机生成6位随机验证码</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public static String createRandomVcode(int len) &#123;</span><br><span class="line">        &#x2F;&#x2F; 验证码</span><br><span class="line">        String vcode &#x3D; &quot;&quot;;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; len; i++) &#123;</span><br><span class="line">            vcode &#x3D; vcode + (int) (Math.random() * 9);</span><br><span class="line">        &#125;</span><br><span class="line">        return vcode;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class JsonMapper extends ObjectMapper &#123;</span><br><span class="line">    private static final long serialVersionUID &#x3D; 3591908322400026138L;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    private static Logger logger &#x3D; LoggerFactory.getLogger(JsonMapper.class);</span><br><span class="line">    private static JsonMapper mapper;</span><br><span class="line"></span><br><span class="line">    public JsonMapper() &#123;</span><br><span class="line">        this(Include.NON_EMPTY);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public JsonMapper(Include include) &#123;</span><br><span class="line">        if (include !&#x3D; null) &#123;</span><br><span class="line">            this.setSerializationInclusion(include);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        this.enableSimple();</span><br><span class="line">        this.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES);</span><br><span class="line">        this.getSerializerProvider().setNullValueSerializer(new JsonSerializer&lt;Object&gt;() &#123;</span><br><span class="line">            public void serialize(Object value, JsonGenerator jgen, SerializerProvider provider) throws IOException, JsonProcessingException &#123;</span><br><span class="line">                jgen.writeString(&quot;&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        this.registerModule((new SimpleModule()).addSerializer(String.class, new JsonSerializer&lt;String&gt;() &#123;</span><br><span class="line">            public void serialize(String value, JsonGenerator jgen, SerializerProvider provider) throws IOException, JsonProcessingException &#123;</span><br><span class="line">                jgen.writeString(StringEscapeUtils.unescapeHtml4(value));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;));</span><br><span class="line">        this.setTimeZone(TimeZone.getDefault());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static JsonMapper getInstance() &#123;</span><br><span class="line">        if (mapper &#x3D;&#x3D; null) &#123;</span><br><span class="line">            mapper &#x3D; (new JsonMapper()).enableSimple();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return mapper;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static JsonMapper nonDefaultMapper() &#123;</span><br><span class="line">        if (mapper &#x3D;&#x3D; null) &#123;</span><br><span class="line">            mapper &#x3D; new JsonMapper(Include.NON_DEFAULT);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return mapper;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String toJson(Object object) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            return this.writeValueAsString(object);</span><br><span class="line">        &#125; catch (IOException var3) &#123;</span><br><span class="line">            logger.warn(&quot;write to json string error:&quot; + object, var3);</span><br><span class="line">            return null;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public &lt;T&gt; T fromJson(String jsonString, Class&lt;T&gt; clazz) &#123;</span><br><span class="line">        if (StringUtils.isEmpty(jsonString)) &#123;</span><br><span class="line">            return null;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                return this.readValue(jsonString, clazz);</span><br><span class="line">            &#125; catch (IOException var4) &#123;</span><br><span class="line">                logger.warn(&quot;parse json string error:&quot; + jsonString, var4);</span><br><span class="line">                return null;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public &lt;T&gt; T fromJson(String jsonString, JavaType javaType) &#123;</span><br><span class="line">        if (StringUtils.isEmpty(jsonString)) &#123;</span><br><span class="line">            return null;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                return this.readValue(jsonString, javaType);</span><br><span class="line">            &#125; catch (IOException var4) &#123;</span><br><span class="line">                logger.warn(&quot;parse json string error:&quot; + jsonString, var4);</span><br><span class="line">                return null;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public JavaType createCollectionType(Class&lt;?&gt; collectionClass, Class... elementClasses) &#123;</span><br><span class="line">        return this.getTypeFactory().constructParametricType(collectionClass, elementClasses);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public &lt;T&gt; T update(String jsonString, T object) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            return this.readerForUpdating(object).readValue(jsonString);</span><br><span class="line">        &#125; catch (JsonProcessingException var4) &#123;</span><br><span class="line">            logger.warn(&quot;update json string:&quot; + jsonString + &quot; to object:&quot; + object + &quot; error.&quot;, var4);</span><br><span class="line">        &#125; catch (IOException var5) &#123;</span><br><span class="line">            logger.warn(&quot;update json string:&quot; + jsonString + &quot; to object:&quot; + object + &quot; error.&quot;, var5);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return null;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String toJsonP(String functionName, Object object) &#123;</span><br><span class="line">        return this.toJson(new JSONPObject(functionName, object));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public JsonMapper enableEnumUseToString() &#123;</span><br><span class="line">        this.enable(SerializationFeature.WRITE_ENUMS_USING_TO_STRING);</span><br><span class="line">        this.enable(DeserializationFeature.READ_ENUMS_USING_TO_STRING);</span><br><span class="line">        return this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public JsonMapper enableJaxbAnnotation() &#123;</span><br><span class="line">        JaxbAnnotationModule module &#x3D; new JaxbAnnotationModule();</span><br><span class="line">        this.registerModule(module);</span><br><span class="line">        return this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public JsonMapper enableSimple() &#123;</span><br><span class="line">        this.configure(Feature.ALLOW_SINGLE_QUOTES, true);</span><br><span class="line">        this.configure(Feature.ALLOW_UNQUOTED_FIELD_NAMES, true);</span><br><span class="line">        return this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public ObjectMapper getMapper() &#123;</span><br><span class="line">        return this;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static String toJsonString(Object object) &#123;</span><br><span class="line">        return getInstance().toJson(object);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static Object fromJsonString(String jsonString, Class&lt;?&gt; clazz) &#123;</span><br><span class="line">        return getInstance().fromJson(jsonString, clazz);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public class JsonUtils &#123;</span><br><span class="line"></span><br><span class="line">    public JsonUtils() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static String renderString(HttpServletResponse response, Object object) &#123;</span><br><span class="line">        return renderString(response, JsonMapper.toJsonString(object), &quot;application&#x2F;json&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static String renderString(HttpServletResponse response, String string, String type) &#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            response.setContentType(type);</span><br><span class="line">            response.setCharacterEncoding(&quot;utf-8&quot;);</span><br><span class="line">            response.getWriter().print(string);</span><br><span class="line">            return null;</span><br><span class="line">        &#125; catch (IOException var4) &#123;</span><br><span class="line">            return null;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud之Eureka</title>
    <url>/2020/09/18/springcloud%E4%B9%8BEurake/</url>
    <content><![CDATA[<h2 id="Eurake-服务注册与发现"><a href="#Eurake-服务注册与发现" class="headerlink" title="Eurake 服务注册与发现"></a>Eurake 服务注册与发现</h2><p>1、首先创建springboot项目，引入依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.3.5.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>
<a id="more"></a>

<p>2、在项目的主入口添加注解@EnableEurekaServer</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@SpringBootApplication</span><br><span class="line">@EnableEurekaServer</span><br><span class="line">public class EurekaserviceApplication &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SpringApplication.run(EurekaserviceApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3、在application.properties文件中进行配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server.port&#x3D;5000</span><br><span class="line">eureka.instance.hostname&#x3D;localhost</span><br><span class="line">#是否向服务注册中心注册自己,默认为true</span><br><span class="line">eureka.client.register-with-eureka&#x3D;false</span><br><span class="line">#是否检索服务</span><br><span class="line">eureka.client.fetch-registry&#x3D;true</span><br><span class="line">eureka.client.serviceUrl.defaultZone&#x3D;http:&#x2F;&#x2F;$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;&#x2F;eureka&#x2F;</span><br></pre></td></tr></table></figure>
<p>4、输入地址<a href="http://localhost:5000/">http://localhost:5000/</a></p>
<p><img src="/assets/resource/springcloud/eureka0.png"></p>
<p>5、EurakeSever 认证 添加依赖 并 在application.properties文件中进行配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-security&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>


<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#添加basic认证</span><br><span class="line"></span><br><span class="line">security.basic.enabled&#x3D;true</span><br><span class="line"></span><br><span class="line">security.user.name&#x3D;user1</span><br><span class="line"></span><br><span class="line">security.user.password&#x3D;password1</span><br></pre></td></tr></table></figure>

<p>6、我们也修改服务端，我们只需要将服务提供端application.properties 中原来的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">eureka.client.service-url.defalutZone&#x3D; http:&#x2F;&#x2F;localhost:8761&#x2F;eureka&#x2F;</span><br><span class="line">变为： eureka.client.serviceurl.defalutZone&#x3D;http:&#x2F;&#x2F;user1:password1@localhost:8761&#x2F;eureka&#x2F;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/assets/resource/springcloud/eureka0.png"></p>
]]></content>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Eureka</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud之Feign</title>
    <url>/2020/09/18/springcloud%E4%B9%8Bfeign/</url>
    <content><![CDATA[<h4 id="1、-Feign介绍"><a href="#1、-Feign介绍" class="headerlink" title="1、 Feign介绍"></a>1、 Feign介绍</h4><p>Feign是Netflix公司开源的轻量级rest客户端，使用Feign可以非常方便的实现Http 客户端，省去了RestTemplate。Spring Cloud引入Feign并且集成了Ribbon实现客户端负载均衡调用。</p>
<h3 id="2、Feign工作原理如下"><a href="#2、Feign工作原理如下" class="headerlink" title="2、Feign工作原理如下"></a>2、Feign工作原理如下</h3><p>（1）、 启动类添加@EnableFeignClients注解，Spring会扫描标记了@FeignClient注解的接口，并生成此接口的代理对象</p>
<p>（2）、@FeignClient(value = “springbootService”, fallback=ServiceFallback.class) 即指定了生产者的服务名称，Feign会从注册中心获取生产者服务列表，并通过负载均衡算法进行服务调用。</p>
<p>（3）、在接口方法 中使用注解@RequestMapping(value = “/service/hello”)，指定调用的url，Feign将根据url进行远程调用。</p>
<a id="more"></a>
<ul>
<li>主程序入口添加了@EnableFeignClients注解开启对FeignClient扫描加载处理。根据Feign Client的开发规范，定义接口并加@FeignClientd注解。</li>
<li>当程序启动时，回进行包扫描，扫描所有@FeignClients的注解的类，并且讲这些信息注入Spring IOC容器中，当定义的的Feign接口中的方法呗调用时，通过JDK的代理方式，来生成具体的RequestTemplate.当生成代理时，Feign会为每个接口方法创建一个RequestTemplate。当生成代理时，Feign会为每个接口方法创建一个RequestTemplate对象，改对象封装可HTTP请求需要的全部信息，如请求参数名，请求方法等信息都是在这个过程中确定的。</li>
<li>然后RequestTemplate生成Request,然后把Request交给Client去处理，这里指的时Client可以时JDK原生的URLConnection,Apache的HttpClient,也可以时OKhttp，最后Client被封装到LoadBalanceClient类，这个类结合Ribbon负载均衡发器服务之间的调用。</li>
</ul>
<h3 id="3、Feign注解剖析"><a href="#3、Feign注解剖析" class="headerlink" title="3、Feign注解剖析"></a>3、Feign注解剖析</h3><p>@FeignClient注解主要被@Target({ElementType.TYPE})修饰，表示该注解主要使用在接口上。它具备了如下的属性：</p>
<ul>
<li><p>name:指定FeignClient的名称，如果使用了Ribbon，name就作为微服务的名称，用于服务发现。</p>
</li>
<li><p>url:url一般用于调试，可以指定@FeignClient调用的地址。</p>
</li>
<li><p>decode404: 当发生404错误时，如果该字段为true，会调用decoder进行解码，否则抛出FeignException.</p>
</li>
<li><p>configuration:Feign配置类，可以自定或者配置Feign的Encoder，Decoder，LogLevel，Contract。</p>
</li>
<li><p>fallback:定义容错的处理类，当调用远程接口失败或者超时时，会调用对应的接口的容错逻辑，fallback指定的类必须实现@Feign标记的接口。</p>
</li>
<li><p>fallbacjFactory:工厂类，用于生成fallback类实例，通过这个属性可以实现每个接口通用的容错逻辑们介绍重复的代码。</p>
</li>
<li><p>path：定义当前FeignClient的统一前缀。</p>
<h3 id="4、上代码"><a href="#4、上代码" class="headerlink" title="4、上代码"></a>4、上代码</h3></li>
</ul>
<p>（1）、主方法入口，添加pom依赖</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@SpringBootApplication</span><br><span class="line">@EnableDiscoveryClient</span><br><span class="line">@ServletComponentScan</span><br><span class="line">@EnableFeignClients</span><br><span class="line">@EnableCircuitBreaker</span><br><span class="line">public class FeignserviceApplication &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SpringApplication.run(FeignserviceApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Bean</span><br><span class="line">    RestTemplate restTemplate() &#123;</span><br><span class="line">        return new RestTemplate();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.commons&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;commons-lang3&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;3.4&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;fastjson&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.2.7&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.fasterxml.jackson.module&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;jackson-module-jaxb-annotations&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.0.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--Spring Cloud Config 客户端依赖--&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-config&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.0.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--Spring Boot Actuator，感应服务端变化--&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-actuator&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.0.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.cloud&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.4.7.RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line"></span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.netflix.hystrix&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;hystrix-javanica&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;RELEASE&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>

<p>（2）、application.properties配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spring.application.name&#x3D;springCloudFeign</span><br><span class="line">server.port&#x3D;6004</span><br><span class="line"></span><br><span class="line">feign.hystrix.enabled&#x3D;true</span><br><span class="line"></span><br><span class="line">eureka.client.service-url.defaultZone&#x3D;http:&#x2F;&#x2F;localhost:5000&#x2F;eureka&#x2F;</span><br></pre></td></tr></table></figure>

<p>（3）、添加feign 调用方法及失败会掉方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Component</span><br><span class="line">@FeignClient(value &#x3D; &quot;springbootService&quot;, fallback&#x3D;ServiceFallback.class) &#x2F;&#x2F;这里的value对应调用服务的spring.applicatoin.name</span><br><span class="line">public interface ServiceFeignClient &#123;</span><br><span class="line"></span><br><span class="line">    @RequestMapping(value &#x3D; &quot;&#x2F;service&#x2F;hello&quot;)</span><br><span class="line">    RestfulResult hello(@RequestBody ServiceInfo serviceInfo);</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class ServiceFallback implements ServiceFeignClient&#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public RestfulResult hello(ServiceInfo serviceInfo) &#123;</span><br><span class="line">        RestfulResult result &#x3D; new RestfulResult();</span><br><span class="line">        result.setData(&quot;服务调用失败&quot;);</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）、controller 层调用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 调用：localhost:6004&#x2F;consumerService?token&#x3D;1</span><br><span class="line">@RequestMapping(&quot;&#x2F;consumerService&quot;)</span><br><span class="line">public void consumerService(HttpServletResponse response, ServiceInfo serviceInfo) &#123;</span><br><span class="line">    RestfulResult restfulResult &#x3D; serviceFeignClient.hello(serviceInfo);</span><br><span class="line">    CommUtils.printDataJason(response, restfulResult);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Feign</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringCloud之Ribbon</title>
    <url>/2020/09/18/springcloud%E4%B9%8Bribbon/</url>
    <content><![CDATA[<h2 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h2><p>Spring Cloud Ribbon是一个基于HTTP和TCP的客户端负载均衡工具，它基于Netflix Ribbon实现。通过Spring Cloud的封装，可以让我们轻松地将面向服务的REST模版请求自动转换成客户端负载均衡的服务调用。集中式负载均衡。</p>
<h2 id="2、贴代码"><a href="#2、贴代码" class="headerlink" title="2、贴代码"></a>2、贴代码</h2><p>（1）、application.properties文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">spring.application.name&#x3D;springbootConsumerRibbon</span><br><span class="line">server.port&#x3D;6007</span><br><span class="line"></span><br><span class="line">eureka.client.service-url.defaultZone&#x3D;http:&#x2F;&#x2F;localhost:5000&#x2F;eureka&#x2F;</span><br></pre></td></tr></table></figure>
<a id="more"></a>

<p>（2）、主入口方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@SpringBootApplication</span><br><span class="line">@ServletComponentScan</span><br><span class="line">@EnableDiscoveryClient</span><br><span class="line">@EnableHystrix</span><br><span class="line">public class RibbonserviceApplication &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SpringApplication.run(RibbonserviceApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line">    @Bean</span><br><span class="line">    @LoadBalanced</span><br><span class="line">    RestTemplate restTemplate()&#123;</span><br><span class="line">        return new RestTemplate();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（3）、接口调用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 调用：localhost:6007&#x2F;consumerServiceRibbon?token&#x3D;1</span><br><span class="line">@RequestMapping(&quot;&#x2F;consumerServiceRibbon&quot;)</span><br><span class="line">@HystrixCommand(fallbackMethod &#x3D; &quot;consumerServiceRibbonFallback&quot;)</span><br><span class="line">public String consumerServiceRibbon(@RequestBody ServiceInfo serviceInfo) &#123;</span><br><span class="line">    String result &#x3D; this.restTemplate.postForObject(&quot;http:&#x2F;&#x2F;springbootService&#x2F;service&#x2F;rest?token&#x3D;1&quot;, serviceInfo, String.class);</span><br><span class="line">    return result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（4）、失败回调</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">public String consumerServiceRibbonFallback(@RequestBody ServiceInfo serviceInfo) &#123;</span><br><span class="line">    return &quot;consumerServiceRibbon异常，端口：&quot; + port + &quot;，Name&#x3D;&quot; + serviceInfo.getName();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>（5）、启动连个生产者提供方法（略去）</p>
]]></content>
      <tags>
        <tag>SpringCloud</tag>
        <tag>Ribbon</tag>
      </tags>
  </entry>
  <entry>
    <title>windows 下部署hadoop</title>
    <url>/2020/09/25/windows%20%E4%B8%8B%E9%83%A8%E7%BD%B2hadoop/</url>
    <content><![CDATA[<h2 id="1、下载hadoop-和配置的文件（待定）"><a href="#1、下载hadoop-和配置的文件（待定）" class="headerlink" title="1、下载hadoop 和配置的文件（待定）"></a>1、下载hadoop 和配置的文件（待定）</h2><p>（1）、各种版本<a href="https://archive.apache.org/dist/hadoop/common/">hadoop</a></p>
<p>（2）、根据版本进行选择bin的内容进行覆盖（支持windows 运行的工具）将bin目录(包含以下.dll和.exe文件)文件替换原来hadoop目录下的bin目录</p>
<h2 id="2、-配置hadoop环境变量"><a href="#2、-配置hadoop环境变量" class="headerlink" title="2、 配置hadoop环境变量"></a>2、 配置hadoop环境变量</h2><p>右键单击我的电脑 –&gt;属性 –&gt;高级环境变量配置 –&gt;高级选项卡 –&gt;环境变量 –&gt; 单击新建HADOOP_HOME和编辑环境变量path如下图 </p>
<a id="more"></a>
<p><img src="/assets/resource/hadoop/deploy/huanbian1.png" alt="系统变量"></p>
<p><img src="/assets/resource/hadoop/deploy/huanbian2.png" alt="path"></p>
<h2 id="3、修改hadoop配置文件"><a href="#3、修改hadoop配置文件" class="headerlink" title="3、修改hadoop配置文件"></a>3、修改hadoop配置文件</h2><p>（1）、编辑“E:＼hadoop-3.0.0\etc\hadoop”下的 <strong>core-site.xml</strong> 文件，将下列文本粘贴进去，并保存；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;E:&#x2F;hadoop-3.0.0&#x2F;workplace&#x2F;tmp&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.name.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;E:&#x2F;hadoop-3.0.0&#x2F;workplace&#x2F;name&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.default.name&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;hdfs:&#x2F;&#x2F;localhost:9500&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>



<p>（2）、编辑“E:＼hadoop-3.0.0\etc\hadoop”目录下的 <strong>mapred-site.xml</strong> (没有就将mapred-site.xml.template重命名为mapred-site.xml)文件，粘贴一下内容并保存；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">       &lt;name&gt;mapreduce.framework.name&lt;&#x2F;name&gt;</span><br><span class="line">       &lt;value&gt;yarn&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">       &lt;name&gt;mapred.job.tracker&lt;&#x2F;name&gt;</span><br><span class="line">       &lt;value&gt;hdfs:&#x2F;&#x2F;localhost:9501&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<p>（3）、编辑“E:＼hadoop-3.0.0\etc\hadoop”目录下的 <strong>hdfs-site.xml</strong> 文件，粘贴以下内容并保存。请自行创建data目录，在这里我是在HADOOP_HOME目录下创建了workplace/data目录；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;!-- 这个参数设置为1，因为是单机版hadoop --&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.data.dir&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;E:&#x2F;hadoop-3.0.0&#x2F;workplace&#x2F;data&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">	&lt;property&gt; </span><br><span class="line">        &lt;name&gt;dfs.webhdfs.enabled&lt;&#x2F;name&gt; </span><br><span class="line">        &lt;value&gt;true&lt;&#x2F;value&gt; </span><br><span class="line">    &lt;&#x2F;property&gt; </span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.http.address&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;localhost:50070&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<p>（4）、编辑“E:＼hadoop-3.0.0\etc\hadoop”目录下的<strong>yarn-site.xml</strong>文件，粘贴以下内容并保存；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">   </span><br><span class="line">	 &lt;!-- Site specific YARN configuration properties --&gt;</span><br><span class="line">    &lt;property&gt;       </span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services&lt;&#x2F;name&gt;       </span><br><span class="line">        &lt;value&gt;mapreduce_shuffle&lt;&#x2F;value&gt;    </span><br><span class="line">    &lt;&#x2F;property&gt;    </span><br><span class="line">    &lt;property&gt;       </span><br><span class="line">        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;&#x2F;name&gt;       </span><br><span class="line">        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;&#x2F;value&gt;    </span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;!-- NodeManager总的可用虚拟CPU个数 --&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;!-- 每个节点可用的最大内存 --&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;2048&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;!-- 中间结果存放位置 --&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.local-dirs&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;E:&#x2F;hadoop-3.0.0&#x2F;workplace&#x2F;tmp&#x2F;nm-local-dir&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.log-dirs&lt;&#x2F;name&gt;</span><br><span class="line">        &lt;value&gt;&#x2F;E:&#x2F;hadoop-3.0.0&#x2F;logs&#x2F;yarn&lt;&#x2F;value&gt;</span><br><span class="line">    &lt;&#x2F;property&gt;</span><br><span class="line"></span><br><span class="line">&lt;&#x2F;configuration&gt;</span><br></pre></td></tr></table></figure>

<p>（5）、编辑“E:＼hadoop-3.0.0\etc\hadoop”目录下的 <strong>hadoop-env.cmd</strong> 文件，将JAVA_HOME用 @rem注释掉，编辑为JAVA_HOME的路径，然后保存；</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@rem set JAVA_HOME&#x3D;%JAVA_HOME%</span><br><span class="line"></span><br><span class="line">set JAVA_HOME&#x3D;C:\PROGRA~1\Java\jdk1.8.0_201</span><br></pre></td></tr></table></figure>

<h2 id="4、运行环境"><a href="#4、运行环境" class="headerlink" title="4、运行环境"></a>4、运行环境</h2><p>（1）、运行cmd窗口，执行“ <strong>hdfs namenode -format</strong> ”；<br>（2）、运行cmd窗口，切换到hadoop的sbin目录，执行“start-all.cmd”，它将会启动以下进程。<br><img src="/assets/resource/hadoop/deploy/c1.png"   /></p>
<img src="/assets/resource/hadoop/deploy/c2.png"  />

<img src="/assets/resource/hadoop/deploy/c3.png"  />

<img src="/assets/resource/hadoop/deploy/c4.png" />

<h2 id="５、接下来上传测试，操作HDFS"><a href="#５、接下来上传测试，操作HDFS" class="headerlink" title="５、接下来上传测试，操作HDFS"></a>５、<strong>接下来上传测试，操作HDFS</strong></h2><p>根据你core-site.xml的配置，接下来你就可以通过：hdfs://localhost:9５00来对hdfs进行操作了。</p>
<p>（1）、创建输入目录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\WINDOWS\system32&gt;hadoop fs -mkdir hdfs:&#x2F;&#x2F;localhost:9500&#x2F;user&#x2F;</span><br><span class="line"></span><br><span class="line">C:\WINDOWS\system32&gt;hadoop fs -mkdir hdfs:&#x2F;&#x2F;localhost:9500&#x2F;user&#x2F;wcinput</span><br></pre></td></tr></table></figure>

<p>（2）、上传数据到目录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\WINDOWS\system32&gt;hadoop fs -put D:\file.txt hdfs:&#x2F;&#x2F;localhost:9500&#x2F;user&#x2F;wcinput</span><br><span class="line"></span><br><span class="line">C:\WINDOWS\system32&gt;hadoop fs -put D:\file１.txt hdfs:&#x2F;&#x2F;localhost:9500&#x2F;user&#x2F;wcinput</span><br></pre></td></tr></table></figure>

<p>（3）、查看文件</p>
<blockquote>
<p>E:\hadoop-3.0.0\bin&gt;hadoop fs -ls  hdfs://localhost:9500/user/wcinput<br>Found 2 items<br>-rw-r–r–   1 Administrator supergroup    3551058 2020-09-18 15:01 hdfs://localhost:9500/user/wcinput/file.txt<br>-rw-r–r–   1 Administrator supergroup     145579 2020-09-18 15:01 hdfs://localhost:9500/user/wcinput/file2.txt</p>
</blockquote>
<h2 id="6、hadoop自带的web控制台GUI"><a href="#6、hadoop自带的web控制台GUI" class="headerlink" title="6、hadoop自带的web控制台GUI"></a>6、hadoop自带的web控制台GUI</h2><p>（1）、资源管理GUI:<a href="http://localhost:8088/%EF%BC%9B">http://localhost:8088/；</a> </p>
<p><img src="/assets/resource/hadoop/deploy/web1.png"></p>
<p>（2）、节点管理GUI:<a href="http://localhost:50070/%EF%BC%9B">http://localhost:50070/；</a> </p>
<p><img src="/assets/resource/hadoop/deploy/web2.png"></p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
</search>
